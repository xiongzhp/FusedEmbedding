{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "torch.manual_seed(8) # for reproduce\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "# then import my own modules\n",
    "from FusedEmbedding import save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class FusedEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, radius, T, input_feature_dim, input_bond_dim,\\\n",
    "            fingerprint_dim, embedding_dim, output_units_num, p_dropout=0.0):\n",
    "        super(FusedEmbedding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=p_dropout)\n",
    "        self.atom_fc = nn.Linear(input_feature_dim, fingerprint_dim)        \n",
    "        self.neighbor_fc = nn.Linear(input_feature_dim+input_bond_dim, fingerprint_dim)\n",
    "        self.atom_GRU = nn.ModuleList([nn.GRUCell(fingerprint_dim, fingerprint_dim) for r in range(radius)])\n",
    "\n",
    "        self.fused_GRU = nn.GRUCell(embedding_dim, fingerprint_dim)\n",
    "        self.output = nn.Linear(fingerprint_dim, output_units_num) \n",
    "        self.radius = radius\n",
    "        self.T = T\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "    def forward(self, atom_list, bond_list, atom_degree_list, bond_degree_list, atom_mask, seq_embeddings):\n",
    "        atom_mask = atom_mask.unsqueeze(2)\n",
    "        batch_size,mol_length,num_atom_feat = atom_list.size()\n",
    "        atom_feature = F.relu(self.atom_fc(atom_list)) * atom_mask\n",
    "\n",
    "        bond_neighbor = [bond_list[i][bond_degree_list[i]] for i in range(batch_size)]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        atom_neighbor = [atom_list[i][atom_degree_list[i]] for i in range(batch_size)]\n",
    "        atom_neighbor = torch.stack(atom_neighbor, dim=0)\n",
    "        # then catenate them\n",
    "        neighbor_feature = torch.cat([atom_neighbor, bond_neighbor],dim=-1)\n",
    "#         print(neighbor_feature.shape, neighbor_feature[0][0])\n",
    "        max_features = torch.max(neighbor_feature,dim=-2)[0]\n",
    "        max_features = F.relu(self.neighbor_fc(max_features))\n",
    "#         print(max_features.shape, max_features[0])\n",
    "        batch_size, mol_length, fingerprint_dim = atom_feature.shape\n",
    "        atom_feature_reshape = atom_feature.view(batch_size*mol_length, fingerprint_dim)\n",
    "        max_features_reshape = max_features.view(batch_size*mol_length, fingerprint_dim)\n",
    "        atom_feature_GRU = self.atom_GRU[0](max_features_reshape, atom_feature_reshape)\n",
    "        atom_feature = atom_feature_GRU.view(batch_size, mol_length, fingerprint_dim) * atom_mask        \n",
    "\n",
    "        for d in range(self.radius-1):\n",
    "            neighbor_feature = [atom_feature[i][atom_degree_list[i]] for i in range(batch_size)]\n",
    "            # neighbor_feature is a list of 3D tensor, so we need to stack them into a 4D tensor first\n",
    "            neighbor_feature = torch.stack(neighbor_feature, dim=0)\n",
    "            # then max-pooling \n",
    "            max_features = torch.max(neighbor_feature,dim=-2)[0]\n",
    "\n",
    "            atom_feature_reshape = atom_feature.view(batch_size*mol_length, fingerprint_dim)\n",
    "            max_features_reshape = max_features.view(batch_size*mol_length, fingerprint_dim)\n",
    "            atom_feature_GRU = self.atom_GRU[d+1](max_features_reshape, atom_feature_reshape)\n",
    "            atom_feature = atom_feature_GRU.view(batch_size, mol_length, fingerprint_dim) * atom_mask\n",
    "        mol_feature = torch.sum(atom_feature,-2)            \n",
    "        fused_feature = mol_feature\n",
    "        for t in range(self.T):\n",
    "            fused_feature = self.fused_GRU(seq_embeddings, fused_feature)\n",
    "        fused_prediction = self.output(self.dropout(F.relu(fused_feature)))\n",
    "        return fused_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "from IPython.display import SVG, display\n",
    "import seaborn as sns; sns.set(color_codes=True)\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    155404\n",
      "0.0     89173\n",
      "2.0     34524\n",
      "Name: class, dtype: int64\n",
      "kinase count: 392\n",
      "similes count: 2140\n",
      "number of all smiles:  2140\n",
      "number of successfully processed smiles:  2140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pytorch/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_name = 'Multi-Targeting'\n",
    "tasks = ['activity']\n",
    "kinase_seq_embedding = pd.read_csv('../data/kinase_seq_embedding.csv')\n",
    "smiles_kinase_class = pd.read_csv('../data/smiles_kinase_class_2.csv')\n",
    "print(smiles_kinase_class['class'].value_counts())\n",
    "print('kinase count:',len(smiles_kinase_class['kinase'].value_counts()))\n",
    "print('similes count:',len(smiles_kinase_class['smiles'].value_counts()))\n",
    "\n",
    "seq_embeddings_dict = {}\n",
    "for kinase in list(set(smiles_kinase_class['kinase'].values)):\n",
    "    seq_embeddings_dict[kinase] = [float(x) for x in kinase_seq_embedding.loc[kinase_seq_embedding['kinase']==kinase].embedding.values[0]\\\n",
    "                                 .replace(\"[\", \"\").replace(\"]\", \"\").replace(\" \", \"\").split(',')]\n",
    "\n",
    "smiles_kinase_class['embedding'] = [seq_embeddings_dict[kinase] for kinase in smiles_kinase_class['kinase'].values]\n",
    "\n",
    "smilesList = list(set(smiles_kinase_class.smiles.values))\n",
    "print(\"number of all smiles: \",len(smilesList))\n",
    "atom_num_dist = []\n",
    "remained_smiles = []\n",
    "canonical_smiles_list = []\n",
    "for smiles in smilesList:\n",
    "    try:        \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        atom_num_dist.append(len(mol.GetAtoms()))\n",
    "        remained_smiles.append(smiles)\n",
    "        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "    except:\n",
    "        print(smiles)\n",
    "        pass\n",
    "print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.set(font_scale=1.5)\n",
    "ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "random_seed = 28\n",
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "start = time.time()\n",
    "\n",
    "batch_size = 500\n",
    "epochs = 100\n",
    "p_dropout = 0.18\n",
    "fingerprint_dim = 180\n",
    "\n",
    "radius = 5\n",
    "T = 3\n",
    "weight_decay = 4.5 # also known as l2_regularization_lambda\n",
    "learning_rate = 2.8\n",
    "embedding_dim = 100\n",
    "output_units_num = 3 # for classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = smiles_kinase_class.sample(frac=1/10, random_state=random_seed) # test set\n",
    "training_data = smiles_kinase_class.drop(test_df.index) # training data\n",
    "\n",
    "# training data is further divided into validation set and train set\n",
    "valid_df = training_data.sample(frac=1/9, random_state=random_seed) # validation set\n",
    "train_df = training_data.drop(valid_df.index) # train set\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.136750749250749, 1.7930559422089927, 8.097711154094133]\n"
     ]
    }
   ],
   "source": [
    "inactive_count = training_data['class'].value_counts()[0]\n",
    "weak_count = training_data['class'].value_counts()[1]\n",
    "potent_count = training_data['class'].value_counts()[2]\n",
    "all_count = len(training_data)\n",
    "# loss weight is inverse proportional to number of samples in each class\n",
    "loss_weight = [all_count/inactive_count, all_count/weak_count, all_count/potent_count]\n",
    "print(loss_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dicts = get_smiles_dicts(smilesList)\n",
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([smilesList[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss() # torch.Tensor(loss_weight)\n",
    "model = FusedEmbedding(radius, T, num_atom_features, num_bond_features,\\\n",
    "            fingerprint_dim, embedding_dim, output_units_num, p_dropout)\n",
    "model.cuda()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146423\n",
      "atom_fc.weight torch.Size([180, 39])\n",
      "atom_fc.bias torch.Size([180])\n",
      "neighbor_fc.weight torch.Size([180, 49])\n",
      "neighbor_fc.bias torch.Size([180])\n",
      "atom_GRU.0.weight_ih torch.Size([540, 180])\n",
      "atom_GRU.0.weight_hh torch.Size([540, 180])\n",
      "atom_GRU.0.bias_ih torch.Size([540])\n",
      "atom_GRU.0.bias_hh torch.Size([540])\n",
      "atom_GRU.1.weight_ih torch.Size([540, 180])\n",
      "atom_GRU.1.weight_hh torch.Size([540, 180])\n",
      "atom_GRU.1.bias_ih torch.Size([540])\n",
      "atom_GRU.1.bias_hh torch.Size([540])\n",
      "atom_GRU.2.weight_ih torch.Size([540, 180])\n",
      "atom_GRU.2.weight_hh torch.Size([540, 180])\n",
      "atom_GRU.2.bias_ih torch.Size([540])\n",
      "atom_GRU.2.bias_hh torch.Size([540])\n",
      "atom_GRU.3.weight_ih torch.Size([540, 180])\n",
      "atom_GRU.3.weight_hh torch.Size([540, 180])\n",
      "atom_GRU.3.bias_ih torch.Size([540])\n",
      "atom_GRU.3.bias_hh torch.Size([540])\n",
      "atom_GRU.4.weight_ih torch.Size([540, 180])\n",
      "atom_GRU.4.weight_hh torch.Size([540, 180])\n",
      "atom_GRU.4.bias_ih torch.Size([540])\n",
      "atom_GRU.4.bias_hh torch.Size([540])\n",
      "fused_GRU.weight_ih torch.Size([540, 100])\n",
      "fused_GRU.weight_hh torch.Size([540, 180])\n",
      "fused_GRU.bias_ih torch.Size([540])\n",
      "fused_GRU.bias_hh torch.Size([540])\n",
      "output.weight torch.Size([3, 180])\n",
      "output.bias torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "# for p in model.parameters():\n",
    "#     if p.dim() > 1:\n",
    "#         nn.init.xavier_uniform_(p)\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, optimizer, loss_function, epoch):\n",
    "    model.train()\n",
    "    np.random.seed(epoch)\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, train_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[train_batch,:]\n",
    "        smiles_list = batch_df.smiles.values\n",
    "        y_val = batch_df['class'].values\n",
    "        seq_embeddings = list(batch_df.embedding.values)\n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\\\n",
    "                                                 torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),torch.Tensor(seq_embeddings))\n",
    "#         print(torch.Tensor(x_atom).size(),torch.Tensor(x_bonds).size(),torch.cuda.LongTensor(x_atom_index).size(),torch.cuda.LongTensor(x_bond_index).size(),torch.Tensor(x_mask).size())\n",
    "#         print(mol_prediction)\n",
    "        model.zero_grad()\n",
    "        # Compute your loss function. (Again, Torch wants the target wrapped in a variable)\n",
    "        loss = loss_function(mol_prediction, torch.cuda.LongTensor(y_val))\n",
    "        # Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "def eval(model, dataset):\n",
    "    model.eval()\n",
    "    y_val_list = []\n",
    "    y_pred_list = []\n",
    "    losses_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, train_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[train_batch,:]\n",
    "        smiles_list = batch_df.smiles.values\n",
    "        y_val = batch_df['class'].values\n",
    "        seq_embeddings = list(batch_df.embedding.values)\n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\\\n",
    "                                                 torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),torch.Tensor(seq_embeddings))\n",
    "\n",
    "        y_pred = torch.argmax(mol_prediction, dim=-1).data.squeeze().cpu().numpy()\n",
    "        \n",
    "        losses = F.cross_entropy(mol_prediction, torch.cuda.LongTensor(y_val), reduction='none').data.squeeze().cpu().numpy()\n",
    "        y_val_list.extend(y_val)\n",
    "        y_pred_list.extend(y_pred)\n",
    "        losses_list.extend(losses)\n",
    "        \n",
    "    eval_losses = np.array(losses_list).mean()\n",
    "    eval_accuracy= accuracy_score(y_val_list, y_pred_list)\n",
    "    return eval_losses, eval_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = 'result_log_5r_3T.csv'\n",
    "with open(log_file,'a') as f:\n",
    "    f.write(','.join(['epoch', 'train_losses','train_accuracy','valid_losses','valid_accuracy'])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:\t0\n",
      "train_losses:1.1268791\n",
      "valid_losses:1.1264672\n",
      "train_accuracy:0.2151190652137889\n",
      "valid_accuracy:0.21898960945897528\n",
      "\n",
      "CPU times: user 12min 46s, sys: 54.1 s, total: 13min 40s\n",
      "Wall time: 14min 47s\n",
      "EPOCH:\t1\n",
      "train_losses:0.6938781\n",
      "valid_losses:0.7012789\n",
      "train_accuracy:0.6952270905271832\n",
      "valid_accuracy:0.6917233966320315\n",
      "\n",
      "CPU times: user 9min 43s, sys: 1min 5s, total: 10min 48s\n",
      "Wall time: 10min 49s\n",
      "EPOCH:\t2\n",
      "train_losses:0.5736151\n",
      "valid_losses:0.5850117\n",
      "train_accuracy:0.7528047617128193\n",
      "valid_accuracy:0.7447868147617341\n",
      "\n",
      "CPU times: user 13min 35s, sys: 52.9 s, total: 14min 28s\n",
      "Wall time: 17min 36s\n",
      "EPOCH:\t3\n",
      "train_losses:0.51090574\n",
      "valid_losses:0.5242193\n",
      "train_accuracy:0.7871560947863903\n",
      "valid_accuracy:0.7826585453242565\n",
      "\n",
      "CPU times: user 13min 32s, sys: 53 s, total: 14min 25s\n",
      "Wall time: 17min 20s\n",
      "EPOCH:\t4\n",
      "train_losses:0.45538813\n",
      "valid_losses:0.46857283\n",
      "train_accuracy:0.8097957282527398\n",
      "valid_accuracy:0.8049802938015048\n",
      "\n",
      "CPU times: user 12min 10s, sys: 51.2 s, total: 13min 1s\n",
      "Wall time: 14min 25s\n",
      "EPOCH:\t5\n",
      "train_losses:0.44260094\n",
      "valid_losses:0.45737997\n",
      "train_accuracy:0.813078587071896\n",
      "valid_accuracy:0.8081691150125403\n",
      "\n",
      "CPU times: user 11min 18s, sys: 53.7 s, total: 12min 12s\n",
      "Wall time: 12min 39s\n",
      "EPOCH:\t6\n",
      "train_losses:0.42473865\n",
      "valid_losses:0.44560912\n",
      "train_accuracy:0.8220672605371706\n",
      "valid_accuracy:0.8127194553923325\n",
      "\n",
      "CPU times: user 12min 16s, sys: 50.5 s, total: 13min 6s\n",
      "Wall time: 16min 4s\n",
      "EPOCH:\t7\n",
      "train_losses:0.43995038\n",
      "valid_losses:0.46190846\n",
      "train_accuracy:0.8131547243159964\n",
      "valid_accuracy:0.8037979218917951\n",
      "\n",
      "CPU times: user 13min 6s, sys: 52.4 s, total: 13min 58s\n",
      "Wall time: 17min 49s\n",
      "EPOCH:\t8\n",
      "train_losses:0.4303243\n",
      "valid_losses:0.45507216\n",
      "train_accuracy:0.8233078497498667\n",
      "valid_accuracy:0.8140093156574705\n",
      "\n",
      "CPU times: user 12min 56s, sys: 50.1 s, total: 13min 46s\n",
      "Wall time: 17min 29s\n",
      "EPOCH:\t9\n",
      "train_losses:0.39455965\n",
      "valid_losses:0.41874132\n",
      "train_accuracy:0.8350867292783533\n",
      "valid_accuracy:0.8237190970978144\n",
      "\n",
      "CPU times: user 13min 6s, sys: 53.3 s, total: 14min\n",
      "Wall time: 17min 56s\n",
      "EPOCH:\t10\n",
      "train_losses:0.3870107\n",
      "valid_losses:0.4171766\n",
      "train_accuracy:0.8364034557351498\n",
      "valid_accuracy:0.8235757792905769\n",
      "\n",
      "CPU times: user 13min 12s, sys: 52.8 s, total: 14min 5s\n",
      "Wall time: 17min 56s\n",
      "EPOCH:\t11\n",
      "train_losses:0.37653065\n",
      "valid_losses:0.41075537\n",
      "train_accuracy:0.8399774275464549\n",
      "valid_accuracy:0.8266929415979936\n",
      "\n",
      "CPU times: user 11min 47s, sys: 53.5 s, total: 12min 41s\n",
      "Wall time: 13min 36s\n",
      "EPOCH:\t12\n",
      "train_losses:0.387004\n",
      "valid_losses:0.42001715\n",
      "train_accuracy:0.8364124130579852\n",
      "valid_accuracy:0.823683267646005\n",
      "\n",
      "CPU times: user 10min 14s, sys: 58.2 s, total: 11min 13s\n",
      "Wall time: 11min 18s\n",
      "EPOCH:\t13\n",
      "train_losses:0.3639899\n",
      "valid_losses:0.40070987\n",
      "train_accuracy:0.8464043066808192\n",
      "valid_accuracy:0.8319957004657829\n",
      "\n",
      "CPU times: user 10min 5s, sys: 58.5 s, total: 11min 3s\n",
      "Wall time: 11min 8s\n",
      "EPOCH:\t14\n",
      "train_losses:0.3674796\n",
      "valid_losses:0.40395895\n",
      "train_accuracy:0.8448278178617975\n",
      "valid_accuracy:0.8313149408814046\n",
      "\n",
      "CPU times: user 10min 16s, sys: 58.2 s, total: 11min 14s\n",
      "Wall time: 11min 19s\n",
      "EPOCH:\t15\n",
      "train_losses:0.3572011\n",
      "valid_losses:0.39638373\n",
      "train_accuracy:0.8494184458149149\n",
      "valid_accuracy:0.8314940881404514\n",
      "\n",
      "CPU times: user 7min 14s, sys: 1min 15s, total: 8min 30s\n",
      "Wall time: 8min 30s\n",
      "EPOCH:\t16\n",
      "train_losses:0.35266003\n",
      "valid_losses:0.39494655\n",
      "train_accuracy:0.8511203371536316\n",
      "valid_accuracy:0.8330705840200645\n",
      "\n",
      "CPU times: user 6min 46s, sys: 1min 19s, total: 8min 6s\n",
      "Wall time: 8min 6s\n",
      "EPOCH:\t17\n",
      "train_losses:0.3465418\n",
      "valid_losses:0.3928125\n",
      "train_accuracy:0.8539777231381085\n",
      "valid_accuracy:0.8362235757792906\n",
      "\n",
      "CPU times: user 6min 39s, sys: 1min 19s, total: 7min 58s\n",
      "Wall time: 7min 58s\n",
      "EPOCH:\t18\n",
      "train_losses:0.34389523\n",
      "valid_losses:0.39134482\n",
      "train_accuracy:0.8546674369964306\n",
      "valid_accuracy:0.835148692225009\n",
      "\n",
      "CPU times: user 6min 31s, sys: 1min 19s, total: 7min 50s\n",
      "Wall time: 7min 50s\n",
      "EPOCH:\t19\n",
      "train_losses:0.3348086\n",
      "valid_losses:0.38500503\n",
      "train_accuracy:0.858151835579382\n",
      "valid_accuracy:0.8377284127552849\n",
      "\n",
      "CPU times: user 6min 30s, sys: 1min 19s, total: 7min 49s\n",
      "Wall time: 7min 49s\n",
      "EPOCH:\t20\n",
      "train_losses:0.33385462\n",
      "valid_losses:0.383073\n",
      "train_accuracy:0.8590968331385116\n",
      "valid_accuracy:0.8369043353636689\n",
      "\n",
      "CPU times: user 6min 54s, sys: 1min 19s, total: 8min 14s\n",
      "Wall time: 8min 14s\n",
      "EPOCH:\t21\n",
      "train_losses:0.33110967\n",
      "valid_losses:0.38291636\n",
      "train_accuracy:0.8609062123512524\n",
      "valid_accuracy:0.837656753851666\n",
      "\n",
      "CPU times: user 6min 50s, sys: 1min 19s, total: 8min 10s\n",
      "Wall time: 8min 10s\n",
      "EPOCH:\t22\n",
      "train_losses:0.3365325\n",
      "valid_losses:0.39164522\n",
      "train_accuracy:0.8571351794375697\n",
      "valid_accuracy:0.837370118237191\n",
      "\n",
      "CPU times: user 6min 45s, sys: 1min 19s, total: 8min 5s\n",
      "Wall time: 8min 4s\n",
      "EPOCH:\t23\n",
      "train_losses:0.32216275\n",
      "valid_losses:0.38131818\n",
      "train_accuracy:0.8646772452649352\n",
      "valid_accuracy:0.8396273737011823\n",
      "\n",
      "CPU times: user 6min 41s, sys: 1min 19s, total: 8min\n",
      "Wall time: 8min\n",
      "EPOCH:\t24\n",
      "train_losses:0.31988633\n",
      "valid_losses:0.3783117\n",
      "train_accuracy:0.8642069858160792\n",
      "valid_accuracy:0.8398423504120387\n",
      "\n",
      "CPU times: user 7min 10s, sys: 1min 17s, total: 8min 27s\n",
      "Wall time: 8min 28s\n",
      "EPOCH:\t25\n",
      "train_losses:0.32008532\n",
      "valid_losses:0.37929899\n",
      "train_accuracy:0.8654207030602693\n",
      "valid_accuracy:0.8389107846649946\n",
      "\n",
      "CPU times: user 12min 57s, sys: 46.5 s, total: 13min 44s\n",
      "Wall time: 18min 42s\n",
      "EPOCH:\t26\n",
      "train_losses:0.3200295\n",
      "valid_losses:0.3834645\n",
      "train_accuracy:0.8664597525091701\n",
      "valid_accuracy:0.8390899319240416\n",
      "\n",
      "CPU times: user 12min 56s, sys: 51.8 s, total: 13min 48s\n",
      "Wall time: 18min 34s\n",
      "EPOCH:\t27\n",
      "train_losses:0.30903673\n",
      "valid_losses:0.37993702\n",
      "train_accuracy:0.8682064304620635\n",
      "valid_accuracy:0.8414905051952705\n",
      "\n",
      "CPU times: user 13min 4s, sys: 50.6 s, total: 13min 55s\n",
      "Wall time: 18min 39s\n",
      "EPOCH:\t28\n",
      "train_losses:0.32602525\n",
      "valid_losses:0.3978278\n",
      "train_accuracy:0.8612241973119075\n",
      "valid_accuracy:0.8344679326406306\n",
      "\n",
      "CPU times: user 13min 9s, sys: 50.9 s, total: 14min\n",
      "Wall time: 18min 49s\n",
      "EPOCH:\t29\n",
      "train_losses:0.31366327\n",
      "valid_losses:0.38232732\n",
      "train_accuracy:0.8675570245565005\n",
      "valid_accuracy:0.8390899319240416\n",
      "\n",
      "CPU times: user 12min 7s, sys: 54 s, total: 13min 1s\n",
      "Wall time: 14min 55s\n",
      "EPOCH:\t30\n",
      "train_losses:0.31105986\n",
      "valid_losses:0.38130003\n",
      "train_accuracy:0.868488586131377\n",
      "valid_accuracy:0.838301683984235\n",
      "\n",
      "CPU times: user 11min 33s, sys: 53.4 s, total: 12min 26s\n",
      "Wall time: 12min 56s\n",
      "EPOCH:\t31\n",
      "train_losses:0.3067722\n",
      "valid_losses:0.38057533\n",
      "train_accuracy:0.8707144808559618\n",
      "valid_accuracy:0.8374417771408097\n",
      "\n",
      "CPU times: user 11min 35s, sys: 52 s, total: 12min 26s\n",
      "Wall time: 12min 59s\n",
      "EPOCH:\t32\n",
      "train_losses:0.30611756\n",
      "valid_losses:0.3816317\n",
      "train_accuracy:0.8704144105409776\n",
      "valid_accuracy:0.841168040128986\n",
      "\n",
      "CPU times: user 11min 22s, sys: 55.3 s, total: 12min 17s\n",
      "Wall time: 12min 43s\n",
      "EPOCH:\t33\n",
      "train_losses:0.3004492\n",
      "valid_losses:0.3754301\n",
      "train_accuracy:0.873347933769555\n",
      "valid_accuracy:0.8423504120386958\n",
      "\n",
      "CPU times: user 11min 35s, sys: 52.2 s, total: 12min 28s\n",
      "Wall time: 13min\n",
      "EPOCH:\t34\n",
      "train_losses:0.29231164\n",
      "valid_losses:0.37679598\n",
      "train_accuracy:0.8756410084154048\n",
      "valid_accuracy:0.84209960587603\n",
      "\n",
      "CPU times: user 11min 50s, sys: 54.5 s, total: 12min 45s\n",
      "Wall time: 13min 18s\n",
      "EPOCH:\t35\n",
      "train_losses:0.29278332\n",
      "valid_losses:0.37638783\n",
      "train_accuracy:0.8753946820374326\n",
      "valid_accuracy:0.8428878538158366\n",
      "\n",
      "CPU times: user 11min 42s, sys: 53.1 s, total: 12min 35s\n",
      "Wall time: 13min 13s\n",
      "EPOCH:\t36\n",
      "train_losses:0.29056\n",
      "valid_losses:0.37652895\n",
      "train_accuracy:0.8780191776281905\n",
      "valid_accuracy:0.84209960587603\n",
      "\n",
      "CPU times: user 11min 36s, sys: 52.8 s, total: 12min 29s\n",
      "Wall time: 12min 59s\n",
      "EPOCH:\t37\n",
      "train_losses:0.28665587\n",
      "valid_losses:0.37469503\n",
      "train_accuracy:0.8786506688880827\n",
      "valid_accuracy:0.844034396273737\n",
      "\n",
      "CPU times: user 9min 6s, sys: 1min 6s, total: 10min 12s\n",
      "Wall time: 10min 13s\n",
      "EPOCH:\t38\n",
      "train_losses:0.28619814\n",
      "valid_losses:0.37552625\n",
      "train_accuracy:0.8795060932188588\n",
      "valid_accuracy:0.8413113579362236\n",
      "\n",
      "CPU times: user 6min 28s, sys: 1min 19s, total: 7min 47s\n",
      "Wall time: 7min 47s\n",
      "EPOCH:\t39\n",
      "train_losses:0.28363895\n",
      "valid_losses:0.37270793\n",
      "train_accuracy:0.8821753754237933\n",
      "valid_accuracy:0.8425653887495521\n",
      "\n",
      "CPU times: user 6min 27s, sys: 1min 20s, total: 7min 47s\n",
      "Wall time: 7min 47s\n",
      "EPOCH:\t40\n",
      "train_losses:0.27988473\n",
      "valid_losses:0.37155944\n",
      "train_accuracy:0.882345564557665\n",
      "valid_accuracy:0.8422429236832677\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 35s, sys: 1min 20s, total: 7min 55s\n",
      "Wall time: 7min 55s\n",
      "EPOCH:\t41\n",
      "train_losses:0.27309382\n",
      "valid_losses:0.37583175\n",
      "train_accuracy:0.8851088986523707\n",
      "valid_accuracy:0.8434252955929774\n",
      "\n",
      "CPU times: user 6min 44s, sys: 1min 21s, total: 8min 5s\n",
      "Wall time: 8min 5s\n",
      "EPOCH:\t42\n",
      "train_losses:0.28270328\n",
      "valid_losses:0.3864104\n",
      "train_accuracy:0.8796852396755658\n",
      "valid_accuracy:0.8439627373701183\n",
      "\n",
      "CPU times: user 6min 26s, sys: 1min 19s, total: 7min 46s\n",
      "Wall time: 7min 46s\n",
      "EPOCH:\t43\n",
      "train_losses:0.2805812\n",
      "valid_losses:0.37934634\n",
      "train_accuracy:0.8810377954237038\n",
      "valid_accuracy:0.8445001791472591\n",
      "\n",
      "CPU times: user 6min 29s, sys: 1min 18s, total: 7min 48s\n",
      "Wall time: 7min 48s\n",
      "EPOCH:\t44\n",
      "train_losses:0.27291295\n",
      "valid_losses:0.37817097\n",
      "train_accuracy:0.8853731396760136\n",
      "valid_accuracy:0.8446076675026872\n",
      "\n",
      "CPU times: user 6min 28s, sys: 1min 20s, total: 7min 48s\n",
      "Wall time: 7min 48s\n",
      "EPOCH:\t45\n",
      "train_losses:0.27662262\n",
      "valid_losses:0.37567812\n",
      "train_accuracy:0.8827172934553321\n",
      "valid_accuracy:0.8421354353278395\n",
      "\n",
      "CPU times: user 6min 30s, sys: 1min 19s, total: 7min 49s\n",
      "Wall time: 7min 49s\n",
      "EPOCH:\t46\n",
      "train_losses:0.26526636\n",
      "valid_losses:0.3734306\n",
      "train_accuracy:0.8893949776290863\n",
      "valid_accuracy:0.8455750627015407\n",
      "\n",
      "CPU times: user 6min 27s, sys: 1min 19s, total: 7min 47s\n",
      "Wall time: 7min 47s\n",
      "EPOCH:\t47\n",
      "train_losses:0.2770388\n",
      "valid_losses:0.37704659\n",
      "train_accuracy:0.8836667696758793\n",
      "valid_accuracy:0.8428520243640273\n",
      "\n",
      "CPU times: user 6min 27s, sys: 1min 20s, total: 7min 48s\n",
      "Wall time: 7min 48s\n",
      "EPOCH:\t48\n",
      "train_losses:0.27119115\n",
      "valid_losses:0.3774898\n",
      "train_accuracy:0.8862957439280548\n",
      "valid_accuracy:0.8427445360085991\n",
      "\n",
      "CPU times: user 6min 28s, sys: 1min 19s, total: 7min 48s\n",
      "Wall time: 7min 48s\n",
      "EPOCH:\t49\n",
      "train_losses:0.2634601\n",
      "valid_losses:0.37240705\n",
      "train_accuracy:0.891150612904815\n",
      "valid_accuracy:0.8451809387316374\n",
      "\n",
      "CPU times: user 6min 26s, sys: 1min 20s, total: 7min 46s\n",
      "Wall time: 7min 46s\n",
      "EPOCH:\t50\n",
      "train_losses:0.25906608\n",
      "valid_losses:0.37331784\n",
      "train_accuracy:0.890268316605533\n",
      "valid_accuracy:0.8479039770691509\n",
      "\n",
      "CPU times: user 6min 27s, sys: 1min 19s, total: 7min 47s\n",
      "Wall time: 7min 47s\n",
      "EPOCH:\t51\n",
      "train_losses:0.25584272\n",
      "valid_losses:0.37067157\n",
      "train_accuracy:0.8944961729838186\n",
      "valid_accuracy:0.8448584736653529\n",
      "\n",
      "CPU times: user 6min 31s, sys: 1min 19s, total: 7min 50s\n",
      "Wall time: 7min 50s\n",
      "EPOCH:\t52\n",
      "train_losses:0.259057\n",
      "valid_losses:0.3748392\n",
      "train_accuracy:0.890129478101585\n",
      "valid_accuracy:0.8460050161232533\n",
      "\n",
      "CPU times: user 6min 39s, sys: 1min 19s, total: 7min 59s\n",
      "Wall time: 7min 59s\n",
      "EPOCH:\t53\n",
      "train_losses:0.25001794\n",
      "valid_losses:0.3731512\n",
      "train_accuracy:0.8946663621176902\n",
      "valid_accuracy:0.8489430311716231\n",
      "\n",
      "CPU times: user 6min 46s, sys: 1min 17s, total: 8min 4s\n",
      "Wall time: 8min 4s\n",
      "EPOCH:\t54\n",
      "train_losses:0.2571432\n",
      "valid_losses:0.3717899\n",
      "train_accuracy:0.8938288524325849\n",
      "valid_accuracy:0.8451092798280186\n",
      "\n",
      "CPU times: user 6min 33s, sys: 1min 19s, total: 7min 52s\n",
      "Wall time: 7min 52s\n",
      "EPOCH:\t55\n",
      "train_losses:0.2547424\n",
      "valid_losses:0.3790194\n",
      "train_accuracy:0.8920732171568562\n",
      "valid_accuracy:0.8455750627015407\n",
      "\n",
      "CPU times: user 6min 28s, sys: 1min 19s, total: 7min 48s\n",
      "Wall time: 7min 48s\n",
      "EPOCH:\t56\n",
      "train_losses:0.25789627\n",
      "valid_losses:0.37537488\n",
      "train_accuracy:0.8918895920387314\n",
      "valid_accuracy:0.8443926907918309\n",
      "\n",
      "CPU times: user 6min 46s, sys: 1min 17s, total: 8min 3s\n",
      "Wall time: 8min 3s\n",
      "EPOCH:\t57\n",
      "train_losses:0.25372237\n",
      "valid_losses:0.3745328\n",
      "train_accuracy:0.8957546768421855\n",
      "valid_accuracy:0.8448584736653529\n",
      "\n",
      "CPU times: user 7min 2s, sys: 1min 17s, total: 8min 20s\n",
      "Wall time: 8min 20s\n",
      "EPOCH:\t58\n",
      "train_losses:0.24945182\n",
      "valid_losses:0.3740725\n",
      "train_accuracy:0.8972595070785244\n",
      "valid_accuracy:0.8450017914725905\n",
      "\n",
      "CPU times: user 6min 59s, sys: 1min 18s, total: 8min 18s\n",
      "Wall time: 8min 18s\n",
      "EPOCH:\t59\n",
      "train_losses:0.24633317\n",
      "valid_losses:0.3733548\n",
      "train_accuracy:0.897761117157304\n",
      "valid_accuracy:0.8470082407739161\n",
      "\n",
      "CPU times: user 12min 25s, sys: 1min 2s, total: 13min 28s\n",
      "Wall time: 19min 49s\n",
      "EPOCH:\t60\n",
      "train_losses:0.24432242\n",
      "valid_losses:0.37438017\n",
      "train_accuracy:0.8977432025116333\n",
      "valid_accuracy:0.8481906126836259\n",
      "\n",
      "CPU times: user 14min 38s, sys: 1min 2s, total: 15min 41s\n",
      "Wall time: 25min 12s\n",
      "EPOCH:\t61\n",
      "train_losses:0.23955241\n",
      "valid_losses:0.37834382\n",
      "train_accuracy:0.8997630788110049\n",
      "valid_accuracy:0.8472590469365818\n",
      "\n",
      "CPU times: user 14min 11s, sys: 1min 2s, total: 15min 14s\n",
      "Wall time: 23min 25s\n",
      "EPOCH:\t62\n",
      "train_losses:0.25485122\n",
      "valid_losses:0.38591883\n",
      "train_accuracy:0.8947424993617907\n",
      "valid_accuracy:0.8385883195987102\n",
      "\n",
      "CPU times: user 14min 8s, sys: 1min 2s, total: 15min 11s\n",
      "Wall time: 23min 58s\n",
      "EPOCH:\t63\n",
      "train_losses:0.2470626\n",
      "valid_losses:0.38137218\n",
      "train_accuracy:0.8977028945588742\n",
      "valid_accuracy:0.8441418846291652\n",
      "\n",
      "CPU times: user 13min 48s, sys: 59.1 s, total: 14min 48s\n",
      "Wall time: 23min 9s\n",
      "EPOCH:\t64\n",
      "train_losses:0.24333377\n",
      "valid_losses:0.37260062\n",
      "train_accuracy:0.9016262019607579\n",
      "valid_accuracy:0.8441418846291652\n",
      "\n",
      "CPU times: user 13min 53s, sys: 1min 1s, total: 14min 55s\n",
      "Wall time: 23min 40s\n",
      "EPOCH:\t65\n",
      "train_losses:0.24485284\n",
      "valid_losses:0.3857159\n",
      "train_accuracy:0.8969504794407047\n",
      "valid_accuracy:0.846900752418488\n",
      "\n",
      "CPU times: user 13min 26s, sys: 50.2 s, total: 14min 16s\n",
      "Wall time: 18min 10s\n",
      "EPOCH:\t66\n",
      "train_losses:0.2364566\n",
      "valid_losses:0.3803166\n",
      "train_accuracy:0.9023607024332567\n",
      "valid_accuracy:0.8470798996775349\n",
      "\n",
      "CPU times: user 13min 2s, sys: 56.5 s, total: 13min 59s\n",
      "Wall time: 19min 11s\n",
      "EPOCH:\t67\n",
      "train_losses:0.23156308\n",
      "valid_losses:0.37961912\n",
      "train_accuracy:0.9040446791263027\n",
      "valid_accuracy:0.8457900394123969\n",
      "\n",
      "CPU times: user 14min 23s, sys: 1min 8s, total: 15min 31s\n",
      "Wall time: 27min 32s\n",
      "EPOCH:\t68\n",
      "train_losses:0.2295448\n",
      "valid_losses:0.37650505\n",
      "train_accuracy:0.9033863158979044\n",
      "valid_accuracy:0.849587961304192\n",
      "\n",
      "CPU times: user 14min 21s, sys: 1min 7s, total: 15min 29s\n",
      "Wall time: 26min 54s\n",
      "EPOCH:\t69\n",
      "train_losses:0.2288082\n",
      "valid_losses:0.37598497\n",
      "train_accuracy:0.9063646257406587\n",
      "valid_accuracy:0.846255822285919\n",
      "\n",
      "CPU times: user 14min 15s, sys: 1min 8s, total: 15min 24s\n",
      "Wall time: 26min 36s\n",
      "EPOCH:\t70\n",
      "train_losses:0.2322801\n",
      "valid_losses:0.3772972\n",
      "train_accuracy:0.9045462892050824\n",
      "valid_accuracy:0.8456825510569689\n",
      "\n",
      "CPU times: user 14min 19s, sys: 1min 8s, total: 15min 27s\n",
      "Wall time: 26min 9s\n",
      "EPOCH:\t71\n",
      "train_losses:0.23273964\n",
      "valid_losses:0.38480377\n",
      "train_accuracy:0.9039237552680255\n",
      "valid_accuracy:0.8456108921533501\n",
      "\n",
      "CPU times: user 13min 51s, sys: 59.6 s, total: 14min 51s\n",
      "Wall time: 21min 36s\n",
      "EPOCH:\t72\n",
      "train_losses:0.23771302\n",
      "valid_losses:0.38270834\n",
      "train_accuracy:0.9021098973938669\n",
      "valid_accuracy:0.8443568613400215\n",
      "\n",
      "CPU times: user 13min 7s, sys: 52.4 s, total: 13min 59s\n",
      "Wall time: 16min 21s\n",
      "EPOCH:\t73\n",
      "train_losses:0.22903107\n",
      "valid_losses:0.3753369\n",
      "train_accuracy:0.9063243177878996\n",
      "valid_accuracy:0.8472948763883913\n",
      "\n",
      "CPU times: user 11min 53s, sys: 57.7 s, total: 12min 51s\n",
      "Wall time: 13min 20s\n",
      "EPOCH:\t74\n",
      "train_losses:0.22426966\n",
      "valid_losses:0.37709257\n",
      "train_accuracy:0.9090652585755169\n",
      "valid_accuracy:0.8474023647438195\n",
      "\n",
      "CPU times: user 14min 46s, sys: 1min 3s, total: 15min 49s\n",
      "Wall time: 35min 33s\n",
      "EPOCH:\t75\n",
      "train_losses:0.22503226\n",
      "valid_losses:0.37973025\n",
      "train_accuracy:0.9090742158983524\n",
      "valid_accuracy:0.8438910784664995\n",
      "\n",
      "CPU times: user 15min 37s, sys: 1min 9s, total: 16min 46s\n",
      "Wall time: 43min 18s\n",
      "EPOCH:\t76\n",
      "train_losses:0.22843708\n",
      "valid_losses:0.3872916\n",
      "train_accuracy:0.903999892512126\n",
      "valid_accuracy:0.8475815120028664\n",
      "\n",
      "CPU times: user 15min 10s, sys: 1min 6s, total: 16min 17s\n",
      "Wall time: 39min 44s\n",
      "EPOCH:\t77\n",
      "train_losses:0.2253372\n",
      "valid_losses:0.38790172\n",
      "train_accuracy:0.9052046524334807\n",
      "valid_accuracy:0.8481189537800071\n",
      "\n",
      "CPU times: user 15min 14s, sys: 1min 7s, total: 16min 21s\n",
      "Wall time: 40min 18s\n",
      "EPOCH:\t78\n",
      "train_losses:0.22466499\n",
      "valid_losses:0.38114825\n",
      "train_accuracy:0.9089667280243281\n",
      "valid_accuracy:0.8479039770691509\n",
      "\n",
      "CPU times: user 15min 9s, sys: 1min 4s, total: 16min 13s\n",
      "Wall time: 40min 16s\n",
      "EPOCH:\t79\n",
      "train_losses:0.22162803\n",
      "valid_losses:0.38135645\n",
      "train_accuracy:0.9095444753472083\n",
      "valid_accuracy:0.8458975277678251\n",
      "\n",
      "CPU times: user 15min 1s, sys: 1min 6s, total: 16min 7s\n",
      "Wall time: 40min 55s\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(80):\n",
    "    train_losses, train_accuracy = eval(model, train_df)\n",
    "    valid_losses, valid_accuracy = eval(model, valid_df)\n",
    "    torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, 'saved_models/model_5r_3T_'+str(epoch)+'.pt')\n",
    "\n",
    "    with open(log_file,'a') as f:\n",
    "        f.write(','.join([str(epoch), str(train_losses), str(train_accuracy),str(valid_losses), str(valid_accuracy), '\\n']))\n",
    "\n",
    "    print(\"EPOCH:\\t\"+str(epoch)+'\\n'\\\n",
    "        +\"train_losses\"+\":\"+str(train_losses)+'\\n'\\\n",
    "        +\"valid_losses\"+\":\"+str(valid_losses)+'\\n'\\\n",
    "        +\"train_accuracy\"+\":\"+str(train_accuracy)+'\\n'\\\n",
    "        +\"valid_accuracy\"+\":\"+str(valid_accuracy)+'\\n'\\\n",
    "        )\n",
    "    %time train(model, train_df, optimizer, loss_function, epoch)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
