{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!conda install -c rdkit rdkit --yes","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting package metadata: done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda\n\n  added / updated specs:\n    - rdkit\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    ca-certificates-2019.5.15  |                0         133 KB\n    openssl-1.0.2s             |       h7b6447c_0         3.1 MB\n    rdkit-2018.09.1.0          |   py36h71b666b_1        20.2 MB  rdkit\n    ------------------------------------------------------------\n                                           Total:        23.5 MB\n\nThe following NEW packages will be INSTALLED:\n\n  rdkit              rdkit/linux-64::rdkit-2018.09.1.0-py36h71b666b_1\n\nThe following packages will be UPDATED:\n\n  ca-certificates                               2019.1.23-0 --> 2019.5.15-0\n  openssl                                 1.0.2r-h7b6447c_0 --> 1.0.2s-h7b6447c_0\n\n\n\nDownloading and Extracting Packages\nopenssl-1.0.2s       | 3.1 MB    | ##################################### | 100% \nrdkit-2018.09.1.0    | 20.2 MB   | ##################################### | 100% \nca-certificates-2019 | 133 KB    | ##################################### | 100% \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\n","name":"stdout"}]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import os\n# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\nimport torch\nimport torch.autograd as autograd\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data as Data\ntorch.manual_seed(8) # for reproduce\n\nimport time\nimport numpy as np\nimport gc\nimport sys\nsys.setrecursionlimit(50000)\nimport pickle\n#then import my own modules\n# from AttentiveGraph import Fingerprint\ntorch.backends.cudnn.benchmark = True\ntorch.set_default_tensor_type('torch.cuda.FloatTensor')\nfrom tensorboardX import SummaryWriter\ntorch.nn.Module.dump_patches = True\nimport copy\nimport pandas as pd\n\n\nfrom rdkit import Chem\n%matplotlib inline\nfrom numpy.polynomial.polynomial import polyfit\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport matplotlib\nfrom IPython.display import SVG, display\nimport seaborn as sns; sns.set(color_codes=True)\n\n","execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":true},"cell_type":"code","source":"# # !mkdir saved_models\n# !mv *.pt saved_models\n# !ls","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"task_name = 'Multi-Targeting'\ntasks = ['activity']\nsub_task1 = ['RET','MKNK1','BRAF','SRC','RPS6KB1','TTK','MAPK15','PDPK1','PAK3']\nsub_task2 = ['AURKA','PAK1','FGFR1','STK11','PAK3','MAP3K7','PIK3CA']\nkinase_seq_embedding = pd.read_csv('../input/kinase_seq_embedding.csv')\nsmiles_kinase_activity = pd.read_csv('../input/smiles_kinase_activity.csv')\nprint('kinase count:',len(smiles_kinase_activity['kinase'].value_counts()))\nprint('similes count:',len(smiles_kinase_activity['smiles'].value_counts()))\n\nseq_embeddings_dict = {}\nfor kinase in list(set(smiles_kinase_activity['kinase'].values)):\n    seq_embeddings_dict[kinase] = [float(x) for x in kinase_seq_embedding.loc[kinase_seq_embedding['kinase']==kinase].embedding.values[0]\\\n                                 .replace(\"[\", \"\").replace(\"]\", \"\").replace(\" \", \"\").split(',')]\n\nsmiles_kinase_activity['embedding'] = [seq_embeddings_dict[kinase] for kinase in smiles_kinase_activity['kinase'].values]\n\nsmilesList = list(set(smiles_kinase_activity.smiles.values))\nprint(\"number of all smiles: \",len(smilesList))\natom_num_dist = []\nremained_smiles = []\ncanonical_smiles_list = []\nfor smiles in smilesList:\n    try:        \n        mol = Chem.MolFromSmiles(smiles)\n        atom_num_dist.append(len(mol.GetAtoms()))\n        remained_smiles.append(smiles)\n        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n    except:\n        print(smiles)\n        pass\nprint(\"number of successfully processed smiles: \", len(remained_smiles))\n\nplt.figure(figsize=(5, 3))\nsns.set(font_scale=1.5)\nax = sns.distplot(atom_num_dist, bins=28, kde=False)\nplt.tight_layout()\nplt.show()\nplt.close()","execution_count":5,"outputs":[{"output_type":"stream","text":"kinase count: 392\nsimiles count: 2140\nnumber of all smiles:  2140\nnumber of successfully processed smiles:  2140\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 360x216 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAU8AAAC/CAYAAAB+KF5fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAF9RJREFUeJzt3X1QFOcdB/AvJ8chLzVgD5LR8TVwEBFQJ1a0TXVgzEkN4ASCcSRDYzAapxMhjWITZtqoozVXR1pMophY6zCM1UpOx/FlNNY/qk0bUYnxogPBtI45WCHlVfbuYPvH5TZuDuFY4e6A72fGGXn2d8ezT8z39tndZy9AkiQJREQ0IBpfd4CIaDhieBIRqcDwJCJSgeFJRKQCw5OISAWGJxGRCgxPIiIVGJ5ERCowPImIVGB4EhGpwPAkIlKB4UlEpALDk4hIhUBfd2AwfPttB3p6RtbDocaPD0NTU7uvuzFscLw8x7FS0mgCEBEROuDXjYjw7OmRRlx4AhiR+zSUOF6e41g9Ok7biYhUYHgSEanA8CQiUoHhSUSkwoi4YESDx9EDiHZHnzU6bSAC+bFLoxzDkxREuwP/tjT0WfN0fDQCdfynQ6Mbjx+IiFRgeBIRqcDwJCJSod/w/Pzzz7Fu3TosWrQIiYmJWLBgAVatWoXq6mq32urqarz44otISkrCggULsGXLFty/f9+tzmaz4d1338VPf/pTJCYm4oUXXsClS5cGZ4+IiLyg3/D873//i+7ubuTk5KCkpASrVq1Cc3MzVq5ciX/84x9yncViQX5+PkRRRHFxMbKzs3Ho0CEUFha6vWdxcTEOHDiAjIwMvPXWW9BoNCgoKMCVK1cGd++IiIZIgCRJA17kev/+faSlpSEhIQF79uwBABQUFODmzZs4efIkQkOdi+wPHz6Mt99+G3/+85+RkpICAKipqUFOTg42bdqE/Px8AIAoili6dCmioqJQUVEx4J1oamofcWt19fpwCEKb139vh+jZ1fZQP7va7qvxGo44VkoaTQDGjw8b+OvU/LKxY8ciMjISra2tAID29nZcvHgRWVlZcnACQGZmJkJCQnDy5Em57dSpU9BqtcjJyZHbdDodsrOzcfnyZTQ2NqrpEhGRV3kcnu3t7WhubsZXX32FnTt34tatW/LR5M2bN+FwOJCQkKB4TVBQEOLj42GxWOQ2i8WCqVOnKkIWABITEyFJkqKWiMhfeTz3+s1vfoPTp08DALRaLZYvX441a9YAAARBAADo9Xq31+n1ely9elX+WRAEREdH91oHQNWRp5pD7uFArw/3+u+UmjsRHhbcZ01IiA76yBAv9chzvhiv4Ypj9eg8Ds9169YhNzcXVqsVZrMZNpsNdrsdQUFB6OrqAuA80vwhnU4nbweArq4uaLXaXusA5/nPgRrp5zy9uWSyU3Sgrb2r75pOEUJ396P/skHE83ie41gpqT3n6XF4GgwGGAwGAEBGRgaef/55bNq0CX/84x8RHOw8UrHZbG6vE0VR3g4AwcHBsNvtvdYB34cofY9LJon8j6pjFa1Wi9TUVJw5cwZdXV3ylNs1fX+QIAiIioqSf9br9b1OzV2vfbCWiMhfqZ7odXV1QZIkdHR0IDY2FoGBgbh+/bqixmazwWKxID4+Xm6Li4tDfX09Ojo6FLXXrl2TtxMR+bt+w7O5udmtrb29HadPn8YTTzyB8ePHIzw8HCkpKTCbzYpQNJvN6OzshNFolNuMRiPsdjsOHz4st9lsNhw9ehSzZ8/u9WISEZG/6fck2fr166HT6TBr1izo9Xp88803OHr0KKxWK3bu3CnXFRYWYvny5cjLy0NOTg6sViv279+PZ555BvPnz5frkpKSYDQaYTKZIAgCJk2ahKqqKty9exfbtm0bmr0kIhpk/a4wOnLkCMxmM2pra9Ha2orw8HAkJyfj5Zdfxty5cxW1n332GUwmE27cuIGwsDCkp6ejqKgIISHK21pEUcSuXbtw/PhxtLS0wGAwoKioSBGyAzHSr7Z7c9UPVxiNfBwrJbVX21Utz/Q3DE+GJwPBcxwrJa8uzyQiGu0YnkREKjA8iYhU8K8TVzSkPFnmOcJOHRMNGYbnKOLJMs+kWPeHuxCRO07biYhUYHgSEanA8CQiUoHhSUSkAsOTiEgFhicRkQoMTyIiFRieREQqMDyJiFRgeBIRqcDwJCJSgeFJRKQCw5OISAWGJxGRCgxPIiIVGJ5ERCowPImIVGB4EhGpwPAkIlKB4UlEpALDk4hIBYYnEZEKDE8iIhX6/d72mpoaVFVV4dNPP8Xdu3fx2GOPYdasWVi/fj0mT56sqK2ursa7776LGzduICwsDEuWLMEbb7yBsWPHKupsNhtKS0thNpvR2tqKuLg4FBYWIiUlZXD3bhQJ0ASgQ3T0WdMjeakzRKNAv+G5b98+VFdXw2g0wmAwQBAEVFRUICsrC0eOHMH06dMBABaLBfn5+XjyySdRXFwMq9WKjz76CHfu3MEHH3ygeM/i4mKcOXMGL730EiZPnoyqqioUFBTg4MGDmDVr1tDs6Qgn2rtx7ZbQZ01SrN5LvSEa+foNz/z8fJhMJgQFBclt6enpeO6551BeXo7t27cDAHbu3InHHnsMBw8eRGhoKABg4sSJePvtt3Hp0iX5qLKmpgYnTpzApk2bkJ+fDwDIysrC0qVLYTKZUFFRMdj7SEQ06Po95zl79mxFcALAlClTEBMTg7q6OgBAe3s7Ll68iKysLDk4ASAzMxMhISE4efKk3Hbq1ClotVrk5OTIbTqdDtnZ2bh8+TIaGxsfeaeIiIaaqgtGkiTh3r17iIiIAADcvHkTDocDCQkJirqgoCDEx8fDYrHIbRaLBVOnTlWELAAkJiZCkiRFLRGRv+p32t6bY8eOoaGhAYWFhQAAQXCea9Pr3c+p6fV6XL16Vf5ZEARER0f3WgdA1ZHn+PFhA37NcKDXhwMApOZOhIcF91mr1QZ6rSYkRAd9ZEifNb7gGi/qH8fq0Q04POvq6vDOO+9gzpw5yMzMBAB0dXUBgNv0HnBOyV3bXbVarbbXOgAQRXGgXUJTUzt6RtilZL0+HILQBgDoFB1oa+/qs95u915NZ6cIobu7zxpve3C8qG8cKyWNJkDVAdiApu2CIODVV1/FuHHjUFpaCo3G+fLgYOeRis1mc3uNKIrydlet3W7vtQ74PkSJiPyZx0eebW1tKCgoQFtbGyorKxVTdNffXdP3BwmCgKioKEVtb1Nz12sfrCUi8lceHXmKoog1a9bg9u3b2LNnD6ZNm6bYHhsbi8DAQFy/fl3RbrPZYLFYEB8fL7fFxcWhvr4eHR0ditpr167J24mI/F2/4dnd3Y3169fj6tWrKC0tRXJysltNeHg4UlJSYDabFaFoNpvR2dkJo9EotxmNRtjtdhw+fFhus9lsOHr0KGbPnt3rxSQiIn/T77R9+/bt+OSTT7Bo0SL873//g9lslreFhoYiLS0NAFBYWIjly5cjLy8POTk5sFqt2L9/P5555hnMnz9ffk1SUhKMRiNMJhMEQcCkSZNQVVWFu3fvYtu2bUOwi0REg6/f8Pzyyy8BAOfPn8f58+cV2yZMmCCH54wZM7B//36YTCZs27YNYWFheOGFF1BUVOT2njt27MCuXbtgNpvR0tICg8GAvXv3Ys6cOYOxTzTEPFlHr9MGIpCPnaERLECSpGF/j89Iv1WpQ3Tg35aGPuuTYvUerW33Vs3T8dEI1am6jVgV3n7jOY6VklduVSIiIieGJxGRCgxPIiIVGJ5ERCowPImIVGB4EhGpwPAkIlKB4UlEpALDk4hIBe8tAaFRhUs4aaRjeNKQ8OSrkOfOeByi/eHLahmu5M8YnuQz/QXs0/HRCPTi+niigeDnOhGRCgxPIiIVGJ5ERCowPImIVGB4EhGpwPAkIlKB4UlEpALDk4hIBd6B7GOOHkC0uy9jlJo70fnd8sYR9t12RCMCw9PHRHvv34wZHhaMtvYuAM5vqyQi/8JpOxGRCgxPIiIVGJ5ERCowPImIVGB4EhGpwPAkIlLBo/BsbGyEyWRCXl4eZs2aBYPBgE8//bTX2nPnzmHZsmWYOXMmFi5ciLKyMjgc7vcxtra2oqSkBPPmzUNycjJeeuklWCyWR9sbIiIv8Sg86+vrUV5ejoaGBhgMhofWXbhwAevWrcO4ceNQUlKCtLQ07N69G9u2bVPU9fT0YPXq1Thx4gRWrlyJN998E01NTcjLy8N//vOfR9sjIiIv8Ogm+RkzZuCf//wnIiIicPbsWaxbt67Xuh07duCpp57Chx9+iDFjxgAAQkNDsXfvXuTl5WHKlCkAgFOnTuHKlSvYvXs30tLSAABLlizBs88+i7KyMuzYsWMQdo2IaOh4dOQZFhaGiIiIPmtqa2tRW1uL3NxcOTgBYMWKFejp6cGZM2fkttOnTyMqKgqpqalyW2RkJJYsWYKzZ8/CbrcPdD+IiLxq0C4Y3bhxAwCQkJCgaI+Ojsbjjz8ubwcAi8WCGTNmICAgQFE7c+ZMdHR0jJipu6MH6BAdff7hunWi4WnQ1rYLgvNbEPV693XYer0ejY2Nitp58+a51UVFRQFwXqCaPn26x797/PiwgXbXKxqbO/HlV0191hgmRyA8LLjXba52rTbwoTUuI7EmJEQHfWRIn+/xIL0+3OPa0Y5j9egGLTy7upwPsQgKCnLbptPpcP/+fUVtb3WuNtd7eaqpqR09fngI1yk65Id7PIzd3nvNgw8GeViNJ+8znGs6O0UI3d19voeLXh8OQWjzqHa041gpaTQBqg7ABm3aHhzsPIKw2Wxu20RRlLe7anurc7U9WEtE5I8GLTxd03XX9P1BgiDIU3JX7YPTeBdX24O1RET+aNDCMz4+HgBw/fp1RXtDQwOsVqu8HQDi4uLwxRdfQJKUU+2amhqEhIRg0qRJg9UtIqIhMWjhGRMTg2nTpuHQoUPofuA8VWVlJTQaDRYvXiy3GY1GNDY24ty5c3Jbc3MzTp06hdTUVGi12sHqFg1jAZqAfu9WcPT4upc0Wnl8wei9994DANTV1QEAzGYzLl++jB/96EdYuXIlAGDDhg1Yu3YtVq1ahfT0dNy6dQsVFRXIzc3F1KlT5fd69tlnkZycjA0bNuDll19GREQEKisr0dPTg1/96leDuX80jIn2bly75X4a6EFPx0cjUMcvRCDv8/hfXWlpqeLnv/3tbwCACRMmyOG5aNEilJWVoaysDJs3b0ZkZCTWrl2L1157TfHaMWPGYO/evdixYwcOHjwIURQxc+ZM/P73v8fkyZMfdZ+IiIacx+F58+ZNj+rS0tLkJZd9GTduHLZu3YqtW7d62gUiIr/BR9IREanA8CQiUoHhSUSkAi9TquTocX7nel/8cMUoEQ0ShqdKot2Bf1sa+qxJinV/SAoRjQycthMRqcDwJCJSgeFJRKQCw5OISAWGJxGRCgxPIiIVGJ5ERCowPImIVGB4EhGpwBVGNOJ5spRWpw1EIA8laAAYnjTiebKUlk+kp4HiZy0RkQoMTyIiFRieREQqMDyJiFRgeBIRqcDwJCJSgeFJRKQCb2yjYS1AE4AO0QGpuROdYu83wvO7pGgojMrw5IqTkUO0d+PaLQHhYcFoa+/qtYbfJUVDYVSGJ1ecENGjYjo8hGs6+DCcChKNbgzPh3BNBx+GU8GRpb8PS4CnckjJZ+Fps9lQWloKs9mM1tZWxMXFobCwECkpKb7qEo1i/X1YAjyVQ0o++xwtLi7GgQMHkJGRgbfeegsajQYFBQW4cuWKr7pEROQxn4RnTU0NTpw4gV//+tfYsGEDcnNzceDAATzxxBMwmUy+6BIR0YD4JDxPnToFrVaLnJwcuU2n0yE7OxuXL19GY2OjL7pFROQxn5zAsVgsmDp1KkJDQxXtiYmJkCQJFosFUVFRHr+fRhMwoN8fOEaDkGDtI9UMxnv0VTNWF4huh9Yrv8tfawbyHg+O11D2t79/a909gM3R3WdNUOAYjOnnsGWw3udhBvr/zEimdiwCJEny+k03S5cuRXR0ND788ENFe21tLX7xi19gy5YtiqNSIiJ/45Npe1dXF7Ra9095nU4HABBF0dtdIiIaEJ+EZ3BwMOx2u1u7KzRdIUpE5K98Ep56vb7Xi0KC4LzPbiDnO4mIfMEn4RkXF4f6+np0dHQo2q9duyZvJyLyZz4JT6PRCLvdjsOHD8ttNpsNR48exezZsxEdHe2LbhERecwntyolJSXBaDTCZDJBEARMmjQJVVVVuHv3LrZt2+aLLhERDYhPblUCnBeHdu3ahePHj6OlpQUGgwFFRUWYP3++L7pDRDQgPgtPIqLhjA/YIiJSgeFJRKQCw9MHampq8Lvf/Q7p6elITk7GwoULUVhYiK+//tqttrq6Gi+++CKSkpKwYMECbNmyBffv3/dBr/1HeXk5DAYDMjMz3bZxvJxqamqwevVqPP3005g1axYyMjJw9OhRRc25c+ewbNkyzJw5EwsXLkRZWRkcjr4fCE3f45NdfWDfvn2orq6G0WiEwWCAIAioqKhAVlYWjhw5gunTpwNwPkAlPz8fTz75JIqLi2G1WvHRRx/hzp07+OCDD3y8F74hCALef/99hISEuG3jeDlduHAB69atw9y5c/H6668jMDAQt2/fxjfffONWM2/ePJSUlODWrVvYvXs3vv32W5SUlPiw98OIRF53+fJlSRRFRVt9fb2UkJAgbdy4UW575ZVXpJ/97GdSe3u73PbXv/5Vio2NlS5evOi1/vqTjRs3Snl5edLKlSuljIwMxTaOlyS1trZKKSkp0ubNm/usS09Pl5YtWyY5HA65befOnVJcXJxUX18/xL0cGTht94HZs2cjKChI0TZlyhTExMSgrq4OANDe3o6LFy8iKytL8ei+zMxMhISE4OTJk17tsz+oqanBsWPHsGnTJrdtHC+n48ePo7W1Fa+//joA57hIP7ihpra2FrW1tcjNzcWYMWPk9hUrVqCnpwdnzpzxap+HK4ann5AkCffu3UNERAQA4ObNm3A4HEhISFDUBQUFIT4+HhaLxRfd9BlJkrB582ZkZWUhPj7ebTvHy+nSpUuYNm0aLly4gJ///OeYM2cO5s6dC5PJhO5u5/NBb9y4AQBuYxUdHY3HH39c3k59Y3j6iWPHjqGhoQFLliwB8P1DUvR692/pfNiDVUayjz/+GLW1tVi/fn2v2zleTl9//TWsViuKi4uxbNky/OlPf0JaWhrKy8uxfft2AByrwcILRn6grq4O77zzDubMmSNfQe7q6gIAt+k94Hxkn2v7aNDe3o4//OEPWL169UOfuMXxcurs7ERLSwveeOMNrF69GgCwePFidHZ2orKyEmvXru13rEbj3Qlq8MjTxwRBwKuvvopx48ahtLQUGo3zP0lwcDAA5wNTfkgURXn7aPD+++9Dq9Xil7/85UNrOF5Orv1cunSpov25556D3W7H559/zrEaJAxPH2pra0NBQQHa2tqwb98+xTTK9XfXFOtBgiCMmmeeNjY24sCBA1ixYgXu3buHO3fu4M6dOxBFEXa7HXfu3EFLSwvH6zuucfjxj3+saHf9zLEaPAxPHxFFEWvWrMHt27exZ88eTJs2TbE9NjYWgYGBuH79uqLdZrPBYrH0etFkJGpqaoLdbofJZEJqaqr859q1a6irq0NqairKy8s5Xt+ZMWMGAKChoUHRbrVaAQCRkZHyWPxwrBoaGmC1WkfNWD0qhqcPdHd3Y/369bh69SpKS0uRnJzsVhMeHo6UlBSYzWbFQ6PNZjM6OzthNBq92WWfmThxInbv3u32JyYmBhMmTMDu3buRlZXF8fqOaz+PHDkit0mShMOHDyMkJATJycmIiYnBtGnTcOjQIfkKPABUVlZCo9Fg8eLFXu/3cMSnKvnA1q1b8Ze//AWLFi2Sr667hIaGIi0tDQDwxRdfYPny5YiJiUFOTg6sViv279+Pn/zkJygvL/dF1/1GXl4eWltbYTab5TaOl9PGjRthNpuRnZ2Np556ChcuXMDf//53vPnmm3jllVcAAOfPn8fatWsxb948pKen49atW6ioqEBubi5++9vf+nYHhgmGpw/k5eXhX//6V6/bJkyYgE8++UT++bPPPoPJZMKNGzcQFhaG9PR0FBUV9bo8cTTpLTwBjhfgPFXx3nvv4eOPP8a9e/cwceJE5OfnY/ny5Yq6s2fPoqysDHV1dYiMjMTzzz+P1157DYGBvAnHEwxPIiIVeM6TiEgFhicRkQoMTyIiFRieREQqMDyJiFRgeBIRqcDwJCJSgeFJRKQCw5OISAWGJxGRCv8HclINLywHE8kAAAAASUVORK5CYII=\n"},"metadata":{}}]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"random_seed = 28\nstart_time = str(time.ctime()).replace(':','-').replace(' ','_')\n\nbatch_size = 500\nepochs = 100\n\np_dropout= 0.1\nfingerprint_dim = 500\n\nweight_decay = 5 # also known as l2_regularization_lambda\nlearning_rate = 2\noutput_units_num = 1 # for regression model","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nclass Model(nn.Module):\n\n    def __init__(self, fingerprint_dim, output_units_num):\n        super(Model, self).__init__()\n        self.embedding1 = nn.Linear(fingerprint_dim, fingerprint_dim)\n        self.embedding2 = nn.Linear(fingerprint_dim, fingerprint_dim)\n        self.fused_embedding = nn.Linear(fingerprint_dim+100, fingerprint_dim)\n        self.output = nn.Linear(fingerprint_dim, output_units_num)\n\n    def forward(self, fingerprints, seq_embeddings):\n        mol_embedding = F.relu(self.embedding1(fingerprints))\n        mol_embedding = F.relu(self.embedding1(mol_embedding))         \n        fused_embedding = F.relu(self.fused_embedding(torch.cat([mol_embedding,seq_embeddings],-1)))                 \n        mol_prediction = self.output(fused_embedding)\n            \n        return mol_prediction","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import rdkit.Chem as Chem\nfrom rdkit.Chem import AllChem\n\ndef smiles_to_fps(data, fp_length, fp_radius=2):\n    return stringlist2intarray(np.array([smile_to_fp(s, fp_length, fp_radius) for s in data]))\n\ndef smile_to_fp(s, fp_length, fp_radius):\n    m = Chem.MolFromSmiles(s)\n    return (AllChem.GetMorganFingerprintAsBitVect(\n        m, fp_radius, nBits=fp_length)).ToBitString()\n\ndef stringlist2intarray(A):\n    return np.array([list(s) for s in A], dtype=int)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = smiles_kinase_activity.sample(frac=1/10, random_state=random_seed) # test set\ntraining_data = smiles_kinase_activity.drop(test_df.index) # training data\n\n# get the stats of the seen dataset (the training data)\n# which will be used to noramlize the dataset. \ncolumns = ['Task','Mean','Standard deviation', 'Mean absolute deviation','ratio']\nmean_list=[]\nstd_list=[]\nmad_list=[]\nratio_list=[]\nfor task in tasks:\n    mean = training_data[task].mean()\n    mean_list.append(mean)\n    std = training_data[task].std()\n    std_list.append(std)\n    mad = training_data[task].mad()\n    mad_list.append(mad)\n    ratio_list.append(std/mad)\n    training_data[task+'_normalized'] = (training_data[task]- mean)/std\n    test_df[task+'_normalized'] = (test_df[task]- mean)/std\n\n# training data is further divided into validation set and train set\nvalid_df = training_data.sample(frac=1/9, random_state=random_seed) # validation set\ntrain_df = training_data.drop(valid_df.index) # train set\ntrain_df = train_df.reset_index(drop=True)\nvalid_df = valid_df.reset_index(drop=True)\ntest_df = test_df.reset_index(drop=True)\n\nlist_of_tuples = list(zip(tasks, mean_list, std_list, mad_list, ratio_list))\nstats  = pd.DataFrame(list_of_tuples, columns = columns)\nstats\n","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"       Task     Mean    ...     Mean absolute deviation     ratio\n0  activity  5.22636    ...                    0.572409  1.383907\n\n[1 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Task</th>\n      <th>Mean</th>\n      <th>Standard deviation</th>\n      <th>Mean absolute deviation</th>\n      <th>ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>activity</td>\n      <td>5.22636</td>\n      <td>0.79216</td>\n      <td>0.572409</td>\n      <td>1.383907</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['Task','Mean','Standard deviation', 'Mean absolute deviation','ratio']\nmean_list=[]\nstd_list=[]\nmad_list=[]\nratio_list=[]\nfor task in tasks:\n    mean = train_df[task].mean()\n    mean_list.append(mean)\n    std = train_df[task].std()\n    std_list.append(std)\n    mad = train_df[task].mad()\n    mad_list.append(mad)\n    ratio_list.append(std/mad)\nlist_of_tuples = list(zip(tasks, mean_list, std_list, mad_list, ratio_list))\nstats  = pd.DataFrame(list_of_tuples, columns = columns)\nstats","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"       Task      Mean    ...     Mean absolute deviation     ratio\n0  activity  5.226356    ...                    0.572286  1.383509\n\n[1 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Task</th>\n      <th>Mean</th>\n      <th>Standard deviation</th>\n      <th>Mean absolute deviation</th>\n      <th>ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>activity</td>\n      <td>5.226356</td>\n      <td>0.791763</td>\n      <td>0.572286</td>\n      <td>1.383509</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['Task','Mean','Standard deviation', 'Mean absolute deviation','ratio']\nmean_list=[]\nstd_list=[]\nmad_list=[]\nratio_list=[]\nfor task in tasks:\n    mean = valid_df[task].mean()\n    mean_list.append(mean)\n    std = valid_df[task].std()\n    std_list.append(std)\n    mad = valid_df[task].mad()\n    mad_list.append(mad)\n    ratio_list.append(std/mad)\nlist_of_tuples = list(zip(tasks, mean_list, std_list, mad_list, ratio_list))\nstats  = pd.DataFrame(list_of_tuples, columns = columns)\nstats","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"       Task     Mean    ...     Mean absolute deviation     ratio\n0  activity  5.22639    ...                    0.573387  1.387095\n\n[1 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Task</th>\n      <th>Mean</th>\n      <th>Standard deviation</th>\n      <th>Mean absolute deviation</th>\n      <th>ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>activity</td>\n      <td>5.22639</td>\n      <td>0.795342</td>\n      <td>0.573387</td>\n      <td>1.387095</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict all values as mean of each ligand will get a MSE of 0.3683609544565635\nsmiles_variance = smiles_kinase_activity.groupby('smiles')['activity'].var(ddof=0) * smiles_kinase_activity.groupby('smiles')['smiles'].value_counts()\nprint(np.sqrt(smiles_variance.sum()/smiles_kinase_activity.shape[0]))\n\n# predict all values as mean of each protein kinase will get a MSE of 0.5583972950594606\nkinase_variance = smiles_kinase_activity.groupby('kinase')['activity'].var(ddof=0) * smiles_kinase_activity.groupby('kinase')['kinase'].value_counts()\nprint(np.sqrt(kinase_variance.sum()/smiles_kinase_activity.shape[0]))","execution_count":12,"outputs":[{"output_type":"stream","text":"0.6067693844481934\n0.7473647274436619\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Model(fingerprint_dim, output_units_num)\nmodel.cuda()\n\nloss_function = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n\nmodel_parameters = filter(lambda p: p.requires_grad, model.parameters())\nparams = sum([np.prod(p.size()) for p in model_parameters])\nprint(params)\nfor name, param in model.named_parameters():\n    if param.requires_grad:\n        print(name, param.data.shape)","execution_count":13,"outputs":[{"output_type":"stream","text":"802001\nembedding1.weight torch.Size([500, 500])\nembedding1.bias torch.Size([500])\nembedding2.weight torch.Size([500, 500])\nembedding2.bias torch.Size([500])\nfused_embedding.weight torch.Size([500, 600])\nfused_embedding.bias torch.Size([500])\noutput.weight torch.Size([1, 500])\noutput.bias torch.Size([1])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model, dataset, optimizer, loss_function):\n    model.train()\n    np.random.seed(epoch)\n    valList = np.arange(0,dataset.shape[0])\n    #shuffle them\n    np.random.shuffle(valList)\n    batch_list = []\n    for i in range(0, dataset.shape[0], batch_size):\n        batch = valList[i:i+batch_size]\n        batch_list.append(batch)   \n    for counter, train_batch in enumerate(batch_list):\n        batch_df = dataset.loc[train_batch,:]\n        smiles_list = batch_df.smiles.values\n        y_true = batch_df['activity_normalized'].values\n        name_list = batch_df.kinase.values\n        seq_embeddings = list(batch_df.embedding.values)\n        \n        fingerprints = smiles_to_fps(batch_df['smiles'].values, fingerprint_dim)\n        y_prediction = model(torch.Tensor(fingerprints), torch.Tensor(seq_embeddings))\n        \n        model.zero_grad()\n        loss = loss_function(y_prediction, torch.Tensor(y_true).view(-1,1))     \n        loss.backward()\n        optimizer.step()\ndef eval(model, dataset):\n    model.eval()\n    eval_MAE_list = []\n    eval_MSE_list = []\n    valList = np.arange(0,dataset.shape[0])\n    batch_list = []\n    for i in range(0, dataset.shape[0], batch_size):\n        batch = valList[i:i+batch_size]\n        batch_list.append(batch) \n    for counter, test_batch in enumerate(batch_list):\n        batch_df = dataset.loc[test_batch,:]\n        smiles_list = batch_df.smiles.values\n        y_true = batch_df['activity_normalized'].values\n        name_list = batch_df.kinase.values\n        seq_embeddings = list(batch_df.embedding.values)\n        \n        fingerprints = smiles_to_fps(batch_df['smiles'].values, fingerprint_dim)\n        y_prediction = model(torch.Tensor(fingerprints), torch.Tensor(seq_embeddings))\n        \n        MAE = F.l1_loss(y_prediction, torch.Tensor(y_true).view(-1,1), reduction='none')        \n        MSE = F.mse_loss(y_prediction, torch.Tensor(y_true).view(-1,1), reduction='none')\n        \n        eval_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n        eval_MSE_list.extend(MSE.data.squeeze().cpu().numpy())\n    eval_MAE_nomalized = np.array(eval_MAE_list).mean()\n    eval_MSE_nomalized = np.array(eval_MSE_list).mean()\n    eval_MAE = eval_MAE_nomalized * std_list[0]\n    eval_MSE = eval_MSE_nomalized * std_list[0] * std_list[0]\n    return eval_MAE, np.sqrt(eval_MSE)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(80):\n    train_MAE, train_RMSE = eval(model, train_df)\n    valid_MAE, valid_RMSE = eval(model, valid_df)\n    print(epoch, train_RMSE, valid_RMSE)\n    torch.save(model, 'model_ecfp_protein_embedding'+start_time+'_'+str(epoch)+'.pt')\n    %time train(model, train_df, optimizer, loss_function)","execution_count":null,"outputs":[{"output_type":"stream","text":"0 0.7971547591576911 0.80070477567334\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Model. It won't be checked for correctness upon loading.\n  \"type \" + obj.__name__ + \". It won't be checked \"\n","name":"stderr"},{"output_type":"stream","text":"CPU times: user 2min 1s, sys: 228 ms, total: 2min 2s\nWall time: 2min 2s\n1 0.5580183200497458 0.569042968383776\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Model. It won't be checked for correctness upon loading.\n  \"type \" + obj.__name__ + \". It won't be checked \"\n","name":"stderr"},{"output_type":"stream","text":"CPU times: user 2min, sys: 176 ms, total: 2min 1s\nWall time: 2min 1s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!nvidia-smi","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}