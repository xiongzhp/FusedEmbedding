{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# !conda install -c rdkit rdkit --yes\n","execution_count":2,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import os\n# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\nimport torch\nimport torch.autograd as autograd\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data as Data\ntorch.manual_seed(8) # for reproduce\n\nimport time\nimport numpy as np\nimport gc\nimport sys\nsys.setrecursionlimit(50000)\nimport pickle\ntorch.backends.cudnn.benchmark = True\ntorch.set_default_tensor_type('torch.cuda.FloatTensor')\ntorch.nn.Module.dump_patches = True\nimport copy\nimport pandas as pd","execution_count":3,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"from rdkit import Chem\n# from rdkit.Chem import AllChem\nfrom rdkit.Chem import QED\n%matplotlib inline\nfrom numpy.polynomial.polynomial import polyfit\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport matplotlib\nfrom IPython.display import SVG, display\nimport seaborn as sns; sns.set(color_codes=True)\nimport pandas as pd","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"task_name = 'Multi-Targeting'\ntasks = ['activity']\nsub_task1 = ['RET','MKNK1','BRAF','SRC','RPS6KB1','TTK','MAPK15','PDPK1','PAK3']\nsub_task2 = ['AURKA','PAK1','FGFR1','STK11','PAK3','MAP3K7','PIK3CA']\nkinase_seq_embedding = pd.read_csv('../input/kinase_seq_embedding.csv')\nsmiles_kinase_activity = pd.read_csv('../input/smiles_kinase_activity.csv')\nprint('kinase count:',len(smiles_kinase_activity['kinase'].value_counts()))\nprint('similes count:',len(smiles_kinase_activity['smiles'].value_counts()))\n\n# seq_embeddings_dict = {}\n# for kinase in list(set(smiles_kinase_activity['kinase'].values)):\n#     seq_embeddings_dict[kinase] = [float(x) for x in kinase_seq_embedding.loc[kinase_seq_embedding['kinase']==kinase].embedding.values[0]\\\n#                                  .replace(\"[\", \"\").replace(\"]\", \"\").replace(\" \", \"\").split(',')]\n\n# smiles_kinase_activity['embedding'] = [seq_embeddings_dict[kinase] for kinase in smiles_kinase_activity['kinase'].values]\n\nsmilesList = list(set(smiles_kinase_activity.smiles.values))\nprint(\"number of all smiles: \",len(smilesList))\natom_num_dist = []\nremained_smiles = []\ncanonical_smiles_list = []\nfor smiles in smilesList:\n    try:        \n        mol = Chem.MolFromSmiles(smiles)\n        atom_num_dist.append(len(mol.GetAtoms()))\n        remained_smiles.append(smiles)\n        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n    except:\n        print(smiles)\n        pass\nprint(\"number of successfully processed smiles: \", len(remained_smiles))\n\nplt.figure(figsize=(5, 3))\nsns.set(font_scale=1.5)\nax = sns.distplot(atom_num_dist, bins=28, kde=False)\nplt.tight_layout()\nplt.show()\nplt.close()","execution_count":5,"outputs":[{"output_type":"stream","text":"kinase count: 392\nsimiles count: 2140\nnumber of all smiles:  2140\nnumber of successfully processed smiles:  2140\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 360x216 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"multi_tasks = list(smiles_kinase_activity['kinase'].unique())","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"multi_tasks","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"['EPHA5',\n 'EPHA8',\n 'EPHB1',\n 'EPHB2',\n 'EPHB3',\n 'EPHB4',\n 'EPHB6',\n 'ABL1',\n 'TNK2',\n 'BRSK2',\n 'WNK2',\n 'AKT1',\n 'AKT2',\n 'AKT3',\n 'ALK',\n 'ACVRL1',\n 'ACVR1',\n 'BMPR1A',\n 'ACVR1B',\n 'TGFBR1',\n 'BMPR1B',\n 'DAPK1',\n 'AURKC',\n 'AXL',\n 'GRK2',\n 'MAP4K2',\n 'BLK',\n 'BRAF',\n 'PTK6',\n 'BTK',\n 'CDK7',\n 'CAMK1',\n 'EGFR',\n 'CAMK2A',\n 'CAMK2B',\n 'CAMK2G',\n 'CAMK4',\n 'CDK1',\n 'CDC7',\n 'EPHA4',\n 'CDK2',\n 'CDK3',\n 'CDK4',\n 'CDK5',\n 'CDK6',\n 'PRKG1',\n 'PRKG2',\n 'CHEK1',\n 'CHEK2',\n 'CSNK1A1',\n 'CSNK1D',\n 'JAK1',\n 'CSNK1E',\n 'CSNK1G2',\n 'CSNK1G3',\n 'CSNK2A1',\n 'CLK1',\n 'CLK2',\n 'CLK3',\n 'JAK2',\n 'MAP3K8',\n 'CSF1R',\n 'CSK',\n 'MARK3',\n 'MAP3K12',\n 'DMPK',\n 'PRKDC',\n 'DYRK1B',\n 'DYRK2',\n 'DYRK4',\n 'EEF2K',\n 'EIF2AK2',\n 'MARK2',\n 'EPHA1',\n 'EPHA2',\n 'EPHA3',\n 'MAPK3',\n 'MAPK1',\n 'PTK2',\n 'FER',\n 'FES',\n 'FGFR1',\n 'FGFR2',\n 'FGFR3',\n 'FGFR4',\n 'FGR',\n 'FLT3',\n 'FLT1',\n 'FLT4',\n 'MTOR',\n 'FYN',\n 'GRK4',\n 'GRK5',\n 'GRK6',\n 'GSK3A',\n 'JAK3',\n 'GSK3B',\n 'HCK',\n 'ERBB2',\n 'ERBB4',\n 'HIPK1',\n 'IGF1R',\n 'CHUK',\n 'IKBKB',\n 'INSR',\n 'IRAK1',\n 'ERN1',\n 'INSRR',\n 'ITK',\n 'MAPK8',\n 'MAPK9',\n 'MAPK10',\n 'MAP4K5',\n 'ROS1',\n 'IKBKE',\n 'NUAK1',\n 'PIM3',\n 'KIT',\n 'CDKL1',\n 'PLK4',\n 'LCK',\n 'LIMK2',\n 'LTK',\n 'LYN',\n 'MAPKAPK2',\n 'MAPKAPK3',\n 'MAPKAPK5',\n 'MARK1',\n 'MAP2K1',\n 'DYRK1A',\n 'MAP2K2',\n 'MAP2K5',\n 'MAP2K6',\n 'MAP3K1',\n 'MAP3K14',\n 'MAP3K2',\n 'MAP3K5',\n 'MERTK',\n 'MET',\n 'MAP2K7',\n 'MYLK',\n 'MAP3K9',\n 'MAP3K10',\n 'MKNK1',\n 'MKNK2',\n 'MAP2K4',\n 'RPS6KA5',\n 'RPS6KA4',\n 'STK3',\n 'MUSK',\n 'PKMYT1',\n 'NEK1',\n 'NEK2',\n 'NEK3',\n 'NEK4',\n 'IRAK4',\n 'ROCK2',\n 'MAPK14',\n 'RPS6KB1',\n 'PAK1',\n 'PAK2',\n 'PAK3',\n 'PRKCH',\n 'NTRK3',\n 'PDGFRA',\n 'PDGFRB',\n 'PDPK1',\n 'EIF2AK3',\n 'PHKG2',\n 'PIM1',\n 'PIM2',\n 'CDK9',\n 'ULK2',\n 'MELK',\n 'CDC42BPA',\n 'PRKACA',\n 'PRKCA',\n 'PRKCB',\n 'PRKCD',\n 'PRKCE',\n 'PRKCG',\n 'PRKCI',\n 'PRKD1',\n 'PRKCQ',\n 'PRKCZ',\n 'PRKX',\n 'PLK1',\n 'PLK3',\n 'PKN1',\n 'PKN2',\n 'RAF1',\n 'RET',\n 'GRK1',\n 'RIPK1',\n 'RIPK2',\n 'ROCK1',\n 'MST1R',\n 'RPS6KA2',\n 'RPS6KA3',\n 'RPS6KA1',\n 'MAPK11',\n 'MAPK12',\n 'MAPK13',\n 'SGK1',\n 'SLK',\n 'PLK2',\n 'MAP3K11',\n 'SRC',\n 'SRPK1',\n 'SYK',\n 'BMPR2',\n 'TEC',\n 'TEK',\n 'TESK1',\n 'TGFBR2',\n 'TIE1',\n 'NTRK1',\n 'NTRK2',\n 'TTK',\n 'TXK',\n 'TYK2',\n 'TYRO3',\n 'ULK1',\n 'VRK1',\n 'WEE1',\n 'YES1',\n 'ZAP70',\n 'DDR1',\n 'KDR',\n 'AURKB',\n 'AURKA',\n 'MAPK7',\n 'DDR2',\n 'LIMK1',\n 'EPHA7',\n 'BMX',\n 'FRK',\n 'NEK6',\n 'AAK1',\n 'PTK2B',\n 'PAK6',\n 'PAK4',\n 'STK26',\n 'TAOK3',\n 'TAOK1',\n 'MAP4K4',\n 'TNIK',\n 'MINK1',\n 'STK33',\n 'MAPK15',\n 'LRRK2',\n 'TSSK2',\n 'HASPIN',\n 'GRK3',\n 'PRKD2',\n 'CAMKK2',\n 'CLK4',\n 'STK17A',\n 'STK17B',\n 'DYRK3',\n 'PRKD3',\n 'TNNI3K',\n 'HIPK2',\n 'EIF2AK1',\n 'MAP3K6',\n 'MAP3K20',\n 'PAK5',\n 'SGK2',\n 'SGK3',\n 'PBK',\n 'TBK1',\n 'GRK7',\n 'SIK1',\n 'WNK3',\n 'EPHA6',\n 'CSNK1G1',\n 'MYLK2',\n 'CAMKK1',\n 'CAMK2D',\n 'TSSK1B',\n 'DAPK3',\n 'STK10',\n 'STK11',\n 'STK16',\n 'HIPK3',\n 'HIPK4',\n 'STK24',\n 'IRAK3',\n 'STK4',\n 'NLK',\n 'ALPK3',\n 'STK38L',\n 'MYO3A',\n 'DSTYK',\n 'NUAK2',\n 'MYLK4',\n 'MYLK3',\n 'WEE2',\n 'SRPK3',\n 'SRPK2',\n 'RIOK2',\n 'RIOK3',\n 'RIOK1',\n 'NEK11',\n 'CDK18',\n 'CDK19',\n 'CDK13',\n 'CDK16',\n 'CDK17',\n 'CDK14',\n 'CDK15',\n 'TTBK1',\n 'MAP3K13',\n 'NEK7',\n 'NEK5',\n 'NEK9',\n 'STK25',\n 'CDC42BPG',\n 'CDC42BPB',\n 'PHKG1',\n 'STK32C',\n 'STK32B',\n 'STK32A',\n 'MYO3B',\n 'OXSR1',\n 'CDKL2',\n 'CDKL5',\n 'CDKL3',\n 'RPS6KB2',\n 'ACTR2',\n 'TAOK2',\n 'CDK8',\n 'PRKAA2',\n 'PRKAA1',\n 'COQ8B',\n 'COQ8A',\n 'PRPF4B',\n 'MAP3K3',\n 'MAP3K4',\n 'ERBB3',\n 'VRK2',\n 'WNK1',\n 'PASK',\n 'ACTR2B',\n 'TRPM6',\n 'CDK11A',\n 'STK35',\n 'STK36',\n 'STK38',\n 'STK39',\n 'SIK3',\n 'SIK2',\n 'BMP2K',\n 'CASK',\n 'MARK4',\n 'TNK1',\n 'MAST1',\n 'LATS1',\n 'MAP4K1',\n 'MAP4K3',\n 'CAMK1G',\n 'MAP2K3',\n 'GAK',\n 'ANKK1',\n 'CSNK2A2',\n 'PNCK',\n 'BRSK1',\n 'HUNK',\n 'ICK',\n 'DCLK1',\n 'DCLK3',\n 'DCLK2',\n 'CAMK1D',\n 'SBK1',\n 'TLK1',\n 'TLK2',\n 'MATK',\n 'ABL2',\n 'MAPK6',\n 'MAPK4',\n 'CSNK1A1L',\n 'PRKACG',\n 'PRKACB',\n 'SRMS',\n 'LATS2',\n 'RIPK4',\n 'CIT',\n 'DAPK2',\n 'ULK3',\n 'SNRK',\n 'RPS6KA6',\n 'MAP3K7']"},"metadata":{}}]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"random_seed = 28\nstart_time = str(time.ctime()).replace(':','-').replace(' ','_')\n\nbatch_size = 500\nepochs = 100\n\nlayers = 3\nfingerprint_dim = 500\n\nweight_decay = 5 # also known as l2_regularization_lambda\nlearning_rate = 2\noutput_units_num = 1 * len(multi_tasks)# for regression model","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nclass Model(nn.Module):\n\n    def __init__(self, fingerprint_dim, layers, output_units_num):\n        super(Model, self).__init__()\n        self.hidden = nn.ModuleList([nn.Linear(fingerprint_dim, fingerprint_dim) for _ in range(layers)])\n        self.output = nn.Linear(fingerprint_dim, output_units_num)\n        self.layers = layers\n\n    def forward(self, fingerprints):\n        for i in range(self.layers):\n            fingerprints = F.relu(self.hidden[i](fingerprints))\n        mol_prediction = self.output(fingerprints)\n            \n        return mol_prediction","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import rdkit.Chem as Chem\nfrom rdkit.Chem import AllChem\n\ndef smiles_to_fps(data, fp_length, fp_radius=2):\n    return stringlist2intarray(np.array([smile_to_fp(s, fp_length, fp_radius) for s in data]))\n\ndef smile_to_fp(s, fp_length, fp_radius):\n    m = Chem.MolFromSmiles(s)\n    return (AllChem.GetMorganFingerprintAsBitVect(\n        m, fp_radius, nBits=fp_length)).ToBitString()\n\ndef stringlist2intarray(A):\n    return np.array([list(s) for s in A], dtype=int)\n\nfingerprints = smiles_to_fps(smiles_kinase_activity['smiles'].values, fingerprint_dim)\nsmiles_kinase_activity['fingerprints'] = [list(i) for i in fingerprints]","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_function = nn.MSELoss()\nmodel = Model(fingerprint_dim, layers, output_units_num)\nmodel.cuda()\noptimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = smiles_kinase_activity.sample(frac=1/10, random_state=random_seed) # test set\ntraining_data = smiles_kinase_activity.drop(test_df.index) # training data\n\n# get the stats of the seen dataset (the training data)\n# which will be used to noramlize the dataset. \ncolumns = ['Task','Mean','Standard deviation', 'Mean absolute deviation','ratio']\nmean_list=[]\nstd_list=[]\nmad_list=[]\nratio_list=[]\nfor task in tasks:\n    mean = training_data[task].mean()\n    mean_list.append(mean)\n    std = training_data[task].std()\n    std_list.append(std)\n    mad = training_data[task].mad()\n    mad_list.append(mad)\n    ratio_list.append(std/mad)\n    training_data[task+'_normalized'] = (training_data[task]- mean)/std\n    test_df[task+'_normalized'] = (test_df[task]- mean)/std\n\n# training data is further divided into validation set and train set\nvalid_df = training_data.sample(frac=1/9, random_state=random_seed) # validation set\ntrain_df = training_data.drop(valid_df.index) # train set\ntrain_df = train_df.reset_index(drop=True)\nvalid_df = valid_df.reset_index(drop=True)\ntest_df = test_df.reset_index(drop=True)\n\nlist_of_tuples = list(zip(tasks, mean_list, std_list, mad_list, ratio_list))\nstats  = pd.DataFrame(list_of_tuples, columns = columns)\nstats\n","execution_count":35,"outputs":[{"output_type":"execute_result","execution_count":35,"data":{"text/plain":"       Task     Mean    ...     Mean absolute deviation     ratio\n0  activity  5.22636    ...                    0.572409  1.383907\n\n[1 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Task</th>\n      <th>Mean</th>\n      <th>Standard deviation</th>\n      <th>Mean absolute deviation</th>\n      <th>ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>activity</td>\n      <td>5.22636</td>\n      <td>0.79216</td>\n      <td>0.572409</td>\n      <td>1.383907</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict all values as mean of each ligand will get a MSE of 0.3683609544565635\nsmiles_variance = smiles_kinase_activity.groupby('smiles')['activity'].var(ddof=0) * smiles_kinase_activity.groupby('smiles')['smiles'].value_counts()\nprint(np.sqrt(smiles_variance.sum()/smiles_kinase_activity.shape[0]))\n\n# predict all values as mean of each protein kinase will get a MSE of 0.5583972950594606\nkinase_variance = smiles_kinase_activity.groupby('kinase')['activity'].var(ddof=0) * smiles_kinase_activity.groupby('kinase')['kinase'].value_counts()\nprint(np.sqrt(kinase_variance.sum()/smiles_kinase_activity.shape[0]))","execution_count":36,"outputs":[{"output_type":"stream","text":"0.6067693844481934\n0.7473647274436619\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict all values as mean of each ligand will get a MSE of 0.3683609544565635\nsmiles_variance = training_data.groupby('smiles')['activity'].var(ddof=0) * training_data.groupby('smiles')['smiles'].value_counts()\nprint(np.sqrt(smiles_variance.sum()/training_data.shape[0]))\n\n# predict all values as mean of each protein kinase will get a MSE of 0.5583972950594606\nkinase_variance = training_data.groupby('kinase')['activity'].var(ddof=0) * training_data.groupby('kinase')['kinase'].value_counts()\nprint(np.sqrt(kinase_variance.sum()/training_data.shape[0]))","execution_count":37,"outputs":[{"output_type":"stream","text":"0.6055113264956725\n0.7465290722867107\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_parameters = filter(lambda p: p.requires_grad, model.parameters())\nfor p in model.parameters():\n    if p.dim() > 1:\n        nn.init.xavier_uniform_(p)\nparams = sum([np.prod(p.size()) for p in model_parameters])\nprint(params)\nfor name, param in model.named_parameters():\n    if param.requires_grad:\n        print(name, param.data.shape)\n        ","execution_count":38,"outputs":[{"output_type":"stream","text":"947892\nhidden.0.weight torch.Size([500, 500])\nhidden.0.bias torch.Size([500])\nhidden.1.weight torch.Size([500, 500])\nhidden.1.bias torch.Size([500])\nhidden.2.weight torch.Size([500, 500])\nhidden.2.bias torch.Size([500])\noutput.weight torch.Size([392, 500])\noutput.bias torch.Size([392])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model, dataset, optimizer, loss_function):\n    model.train()\n    np.random.seed(epoch)\n    valList = np.arange(0,dataset.shape[0])\n    #shuffle them\n    np.random.shuffle(valList)\n    batch_list = []\n    for i in range(0, dataset.shape[0], batch_size):\n        batch = valList[i:i+batch_size]\n        batch_list.append(batch)   \n    for counter, train_batch in enumerate(batch_list):\n        batch_df = dataset.loc[train_batch,:]\n        smiles_list = batch_df.smiles.values\n        y_val = batch_df['activity_normalized'].values\n#         seq_embeddings = list(batch_df.embedding.values)\n        tasks_mask = torch.cuda.ByteTensor([np.array([x == task for task in multi_tasks]) for x in batch_df['kinase']])\n        mol_prediction = model(torch.Tensor(list(batch_df['fingerprints'].values)))\n        mol_prediction = torch.masked_select(mol_prediction, tasks_mask)\n        \n        model.zero_grad()\n        # Compute your loss function. (Again, Torch wants the target wrapped in a variable)\n        loss = loss_function(mol_prediction, torch.Tensor(y_val))\n        print(loss)\n        # Do the backward pass and update the gradient\n        loss.backward()\n        optimizer.step()\n        \ndef eval(model, dataset):\n    model.eval()\n    eval_MAE_list = []\n    eval_MSE_list = []\n    valList = np.arange(0,dataset.shape[0])\n    batch_list = []\n    for i in range(0, dataset.shape[0], batch_size):\n        batch = valList[i:i+batch_size]\n        batch_list.append(batch)   \n    for counter, train_batch in enumerate(batch_list):\n        batch_df = dataset.loc[train_batch,:]\n        smiles_list = batch_df.smiles.values\n        y_val = batch_df['activity_normalized'].values\n        \n        tasks_mask = torch.cuda.ByteTensor([np.array([x == task for task in multi_tasks]) for x in batch_df['kinase']])\n        mol_prediction = model(torch.Tensor(list(batch_df['fingerprints'].values)))        \n        mol_prediction = torch.masked_select(mol_prediction, tasks_mask)\n        MAE = F.l1_loss(mol_prediction, torch.Tensor(y_val), reduction='none')\n        MSE = F.mse_loss(mol_prediction, torch.Tensor(y_val), reduction='none')\n        eval_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n        eval_MSE_list.extend(MSE.data.squeeze().cpu().numpy())\n    eval_MAE_nomalized = np.array(eval_MAE_list).mean()\n    eval_MSE_nomalized = np.array(eval_MSE_list).mean()\n    eval_MAE = eval_MAE_nomalized * std_list[0]\n    eval_MSE = eval_MSE_nomalized * std_list[0] * std_list[0]\n    return eval_MAE, eval_MSE","execution_count":42,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"for epoch in range(60):\n    valid_MAE, valid_MSE = eval(model, valid_df)\n    train_MAE, train_MSE = eval(model, train_df)\n    print(epoch, np.sqrt(train_MSE), np.sqrt(valid_MSE))\n   \n    %time train(model, train_df, optimizer, loss_function)\n","execution_count":43,"outputs":[{"output_type":"stream","text":"0 0.7916718941900965 0.795276485690604\nCPU times: user 27.7 s, sys: 168 ms, total: 27.8 s\nWall time: 27.9 s\n1 0.7479210083804481 0.7550478559843463\nCPU times: user 28.1 s, sys: 148 ms, total: 28.2 s\nWall time: 28.3 s\n2 0.7471352499763476 0.7545078555755179\nCPU times: user 27.7 s, sys: 188 ms, total: 27.9 s\nWall time: 27.9 s\n3 0.7469307943587368 0.7542873240030664\nCPU times: user 27.5 s, sys: 152 ms, total: 27.7 s\nWall time: 27.7 s\n4 0.7467005113777387 0.7539873858510072\nCPU times: user 27.5 s, sys: 180 ms, total: 27.7 s\nWall time: 27.7 s\n5 0.7468902070045133 0.7537109750692863\nCPU times: user 27.7 s, sys: 184 ms, total: 27.9 s\nWall time: 27.9 s\n6 0.7467267335640903 0.7541282563260066\nCPU times: user 27.5 s, sys: 192 ms, total: 27.7 s\nWall time: 27.8 s\n7 0.7469530025449747 0.7543833682709522\nCPU times: user 27.5 s, sys: 180 ms, total: 27.7 s\nWall time: 27.7 s\n8 0.7467615447861513 0.7538998989831791\nCPU times: user 27.6 s, sys: 148 ms, total: 27.8 s\nWall time: 27.8 s\n9 0.6849872768500895 0.6940750326436803\nCPU times: user 27.8 s, sys: 164 ms, total: 27.9 s\nWall time: 28 s\n10 0.5832101250958807 0.5981845265882184\nCPU times: user 27.5 s, sys: 148 ms, total: 27.7 s\nWall time: 27.7 s\n11 0.5719862146255493 0.5869353192131295\nCPU times: user 27.4 s, sys: 192 ms, total: 27.6 s\nWall time: 27.6 s\n12 0.571584864798448 0.5852638620872423\nCPU times: user 27.6 s, sys: 160 ms, total: 27.7 s\nWall time: 27.8 s\n13 0.5667554403939246 0.5820005417983103\nCPU times: user 27.5 s, sys: 152 ms, total: 27.7 s\nWall time: 27.7 s\n14 0.56753417356142 0.5825610270021817\nCPU times: user 27.7 s, sys: 136 ms, total: 27.8 s\nWall time: 27.9 s\n15 0.5646290544102938 0.5790564494591328\nCPU times: user 27.7 s, sys: 152 ms, total: 27.9 s\nWall time: 27.9 s\n16 0.5671740566402069 0.5833214172158108\nCPU times: user 27.9 s, sys: 176 ms, total: 28.1 s\nWall time: 28.1 s\n17 0.5623096776137034 0.5766809171425011\nCPU times: user 27.6 s, sys: 160 ms, total: 27.8 s\nWall time: 27.8 s\n18 0.5620375917199273 0.5758033548221732\nCPU times: user 27.6 s, sys: 140 ms, total: 27.8 s\nWall time: 27.8 s\n19 0.5625119185454814 0.576764611697081\nCPU times: user 27.8 s, sys: 172 ms, total: 28 s\nWall time: 28 s\n20 0.558733559460649 0.5727672722222146\nCPU times: user 27.7 s, sys: 176 ms, total: 27.8 s\nWall time: 27.9 s\n21 0.5619955977911077 0.5775358070281428\nCPU times: user 27.6 s, sys: 180 ms, total: 27.8 s\nWall time: 27.8 s\n22 0.5598751007573005 0.5734428825735851\nCPU times: user 27.6 s, sys: 136 ms, total: 27.8 s\nWall time: 27.8 s\n23 0.5605177892401142 0.5752094305805449\nCPU times: user 27.6 s, sys: 184 ms, total: 27.8 s\nWall time: 27.8 s\n24 0.5609871338029316 0.5777175035979012\nCPU times: user 27.6 s, sys: 152 ms, total: 27.8 s\nWall time: 27.8 s\n25 0.5601328121969266 0.5769793537838226\nCPU times: user 27.6 s, sys: 148 ms, total: 27.8 s\nWall time: 27.8 s\n26 0.5610668363347125 0.5753389132733084\nCPU times: user 27.6 s, sys: 228 ms, total: 27.8 s\nWall time: 27.9 s\n27 0.5611534262527429 0.5764940927628652\nCPU times: user 27.7 s, sys: 136 ms, total: 27.9 s\nWall time: 27.9 s\n28 0.5566798402323596 0.5720213941242153\nCPU times: user 27.5 s, sys: 160 ms, total: 27.6 s\nWall time: 27.7 s\n29 0.5559323097265809 0.572484411016921\nCPU times: user 27.7 s, sys: 136 ms, total: 27.9 s\nWall time: 27.9 s\n30 0.5574518486946122 0.5746559642106492\nCPU times: user 27.9 s, sys: 168 ms, total: 28.1 s\nWall time: 28.1 s\n31 0.5576154894600112 0.5730913735069093\nCPU times: user 27.6 s, sys: 212 ms, total: 27.8 s\nWall time: 27.9 s\n32 0.557334686146486 0.5751511977548639\nCPU times: user 27.7 s, sys: 156 ms, total: 27.9 s\nWall time: 27.9 s\n33 0.5593186647273397 0.5753628690904744\nCPU times: user 27.7 s, sys: 140 ms, total: 27.9 s\nWall time: 27.9 s\n34 0.5587391825972144 0.5721384909579943\nCPU times: user 27.8 s, sys: 164 ms, total: 28 s\nWall time: 28 s\n35 0.5589175371996155 0.5748086394779216\nCPU times: user 27.8 s, sys: 148 ms, total: 28 s\nWall time: 28 s\n36 0.556611957997347 0.5735679058550416\nCPU times: user 27.7 s, sys: 184 ms, total: 27.9 s\nWall time: 27.9 s\n37 0.5555775818093798 0.574164570413571\nCPU times: user 27.9 s, sys: 152 ms, total: 28.1 s\nWall time: 28.1 s\n38 0.5534130638166888 0.5713757542799084\nCPU times: user 27.7 s, sys: 132 ms, total: 27.8 s\nWall time: 27.8 s\n39 0.555528585548393 0.5727731820446432\nCPU times: user 27.8 s, sys: 136 ms, total: 27.9 s\nWall time: 27.9 s\n40 0.5610287032027619 0.5759179291904748\nCPU times: user 27.4 s, sys: 196 ms, total: 27.6 s\nWall time: 27.6 s\n41 0.55397482405325 0.5711661088067016\nCPU times: user 27.7 s, sys: 196 ms, total: 27.9 s\nWall time: 27.9 s\n42 0.555381823379666 0.5742306219421681\nCPU times: user 27.5 s, sys: 168 ms, total: 27.7 s\nWall time: 27.7 s\n43 0.5558036559569998 0.5745193616109986\nCPU times: user 27.6 s, sys: 168 ms, total: 27.8 s\nWall time: 27.8 s\n44 0.5550222116726331 0.5740565200482516\nCPU times: user 27.7 s, sys: 164 ms, total: 27.8 s\nWall time: 27.9 s\n45 0.5536668249401138 0.5716659686143138\nCPU times: user 27.6 s, sys: 168 ms, total: 27.7 s\nWall time: 27.8 s\n46 0.5554287955332899 0.575860320098447\nCPU times: user 27.6 s, sys: 180 ms, total: 27.8 s\nWall time: 27.8 s\n47 0.5503509544621883 0.5698092131637842\nCPU times: user 27.6 s, sys: 132 ms, total: 27.7 s\nWall time: 27.8 s\n48 0.5520815380400698 0.5718695117425107\nCPU times: user 27.9 s, sys: 156 ms, total: 28.1 s\nWall time: 28.1 s\n49 0.5560564606435283 0.5735750138195796\nCPU times: user 27.5 s, sys: 140 ms, total: 27.7 s\nWall time: 27.7 s\n50 0.5499905185577901 0.5683561967029307\nCPU times: user 27.5 s, sys: 168 ms, total: 27.7 s\nWall time: 27.7 s\n51 0.5494396271957089 0.5695515129972033\nCPU times: user 27.6 s, sys: 188 ms, total: 27.8 s\nWall time: 27.8 s\n52 0.5384222755823354 0.559033732402229\nCPU times: user 27.6 s, sys: 168 ms, total: 27.8 s\nWall time: 27.8 s\n53 0.5328468422884891 0.5564038585307185\nCPU times: user 27.7 s, sys: 148 ms, total: 27.9 s\nWall time: 27.9 s\n54 0.532387132383838 0.5526284929319082\nCPU times: user 27.7 s, sys: 128 ms, total: 27.8 s\nWall time: 27.9 s\n55 0.5283899543883189 0.5499764410107012\nCPU times: user 27.6 s, sys: 168 ms, total: 27.8 s\nWall time: 27.8 s\n56 0.5299044246840767 0.5524783200690508\nCPU times: user 27.7 s, sys: 140 ms, total: 27.8 s\nWall time: 27.8 s\n57 0.527940993599895 0.5517965290018515\nCPU times: user 27.9 s, sys: 156 ms, total: 28 s\nWall time: 28 s\n58 0.5264238055677284 0.5507159596144773\nCPU times: user 27.5 s, sys: 164 ms, total: 27.7 s\nWall time: 27.7 s\n59 0.5224787074057365 0.5497693166003438\nCPU times: user 27.6 s, sys: 164 ms, total: 27.8 s\nWall time: 27.8 s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(60,150):\n    valid_MAE, valid_MSE = eval(model, valid_df)\n    train_MAE, train_MSE = eval(model, train_df)\n    print(epoch, np.sqrt(train_MSE), np.sqrt(valid_MSE))\n   \n    %time train(model, train_df, optimizer, loss_function)\n","execution_count":44,"outputs":[{"output_type":"stream","text":"60 0.5269524799673178 0.553279599124005\nCPU times: user 27.6 s, sys: 120 ms, total: 27.8 s\nWall time: 27.8 s\n61 0.5224790474466388 0.5494352703918886\nCPU times: user 27.5 s, sys: 180 ms, total: 27.7 s\nWall time: 27.7 s\n62 0.5187573612376194 0.5463355321474553\nCPU times: user 27.6 s, sys: 160 ms, total: 27.8 s\nWall time: 27.8 s\n63 0.5227278264902651 0.5494537865695379\nCPU times: user 27.4 s, sys: 148 ms, total: 27.6 s\nWall time: 27.6 s\n64 0.5181603268263854 0.5461489253907957\nCPU times: user 27.5 s, sys: 208 ms, total: 27.7 s\nWall time: 27.8 s\n65 0.5184128378047016 0.5448853372082901\nCPU times: user 27.4 s, sys: 232 ms, total: 27.6 s\nWall time: 27.6 s\n66 0.5199966510926546 0.5472969477878535\nCPU times: user 27.6 s, sys: 188 ms, total: 27.7 s\nWall time: 27.8 s\n67 0.5172944215734122 0.5458148391813858\nCPU times: user 27.5 s, sys: 172 ms, total: 27.7 s\nWall time: 27.7 s\n68 0.5145917395018107 0.5428862814076632\nCPU times: user 27.5 s, sys: 152 ms, total: 27.7 s\nWall time: 27.7 s\n69 0.5173810176713366 0.5461955616571638\nCPU times: user 27.9 s, sys: 180 ms, total: 28.1 s\nWall time: 28.2 s\n70 0.5133201836850302 0.539113244787179\nCPU times: user 27.7 s, sys: 164 ms, total: 27.9 s\nWall time: 27.9 s\n71 0.5105872173260043 0.5407993036420035\nCPU times: user 27.8 s, sys: 124 ms, total: 27.9 s\nWall time: 28 s\n72 0.5149725940076998 0.5442117656924728\nCPU times: user 27.7 s, sys: 156 ms, total: 27.8 s\nWall time: 27.9 s\n73 0.5145707876875854 0.5447639271639896\nCPU times: user 27.8 s, sys: 160 ms, total: 28 s\nWall time: 28 s\n74 0.5099107918722998 0.5401828534867296\nCPU times: user 27.6 s, sys: 224 ms, total: 27.8 s\nWall time: 27.9 s\n75 0.5110792528010366 0.5404195723972348\nCPU times: user 27.5 s, sys: 180 ms, total: 27.7 s\nWall time: 27.8 s\n76 0.5064969119854542 0.5391154475570545\nCPU times: user 27.6 s, sys: 136 ms, total: 27.8 s\nWall time: 27.8 s\n77 0.5123281906382589 0.5412086075523224\nCPU times: user 27.6 s, sys: 176 ms, total: 27.8 s\nWall time: 27.8 s\n78 0.504186303807129 0.5352840067083018\nCPU times: user 27.7 s, sys: 176 ms, total: 27.8 s\nWall time: 27.9 s\n79 0.5053950879352704 0.5368808721418787\nCPU times: user 27.5 s, sys: 188 ms, total: 27.7 s\nWall time: 27.7 s\n80 0.5012597116731224 0.532126122867532\nCPU times: user 27.6 s, sys: 176 ms, total: 27.7 s\nWall time: 27.8 s\n81 0.503596003197483 0.5352256753470342\nCPU times: user 27.7 s, sys: 196 ms, total: 27.9 s\nWall time: 27.9 s\n82 0.5034403982815852 0.5349047304160041\nCPU times: user 27.4 s, sys: 180 ms, total: 27.6 s\nWall time: 27.7 s\n83 0.5010025494569332 0.5335034945141147\nCPU times: user 27.4 s, sys: 168 ms, total: 27.6 s\nWall time: 27.6 s\n84 0.4996081199606886 0.530260068373502\nCPU times: user 27.6 s, sys: 136 ms, total: 27.7 s\nWall time: 27.7 s\n85 0.500076141699036 0.5348717949261735\nCPU times: user 27.3 s, sys: 224 ms, total: 27.5 s\nWall time: 27.6 s\n86 0.5011332182366977 0.5334616557857171\nCPU times: user 27.4 s, sys: 144 ms, total: 27.5 s\nWall time: 27.6 s\n87 0.5005212892263092 0.5327898411998148\nCPU times: user 27.6 s, sys: 180 ms, total: 27.7 s\nWall time: 27.8 s\n88 0.49954268397120993 0.534481151908883\nCPU times: user 27.6 s, sys: 136 ms, total: 27.8 s\nWall time: 27.8 s\n89 0.49936465694608045 0.534407317916787\nCPU times: user 27.8 s, sys: 128 ms, total: 27.9 s\nWall time: 28 s\n90 0.49597384827042706 0.5291297062873077\nCPU times: user 27.4 s, sys: 164 ms, total: 27.6 s\nWall time: 27.6 s\n91 0.4975947520686793 0.5306980460883688\nCPU times: user 27.9 s, sys: 164 ms, total: 28.1 s\nWall time: 28.1 s\n92 0.49488927604274774 0.5304886121044622\nCPU times: user 27.4 s, sys: 172 ms, total: 27.6 s\nWall time: 27.6 s\n93 0.4978379536761474 0.529702302992433\nCPU times: user 27.4 s, sys: 152 ms, total: 27.5 s\nWall time: 27.6 s\n94 0.4942007871877912 0.5289762739576119\nCPU times: user 27.6 s, sys: 148 ms, total: 27.7 s\nWall time: 27.8 s\n95 0.4946889524846447 0.5294808725201724\nCPU times: user 27.8 s, sys: 164 ms, total: 28 s\nWall time: 28 s\n96 0.4963826080389421 0.5293183205968499\nCPU times: user 27.3 s, sys: 176 ms, total: 27.5 s\nWall time: 27.5 s\n97 0.4967568866654849 0.5293039405707367\nCPU times: user 27.5 s, sys: 144 ms, total: 27.7 s\nWall time: 27.7 s\n98 0.499223654349277 0.5337558595173038\nCPU times: user 27.6 s, sys: 156 ms, total: 27.8 s\nWall time: 27.8 s\n99 0.49620120473808255 0.5283897420281425\nCPU times: user 27.7 s, sys: 164 ms, total: 27.9 s\nWall time: 27.9 s\n100 0.49431148125029956 0.5283001892136154\nCPU times: user 27.7 s, sys: 196 ms, total: 27.9 s\nWall time: 27.9 s\n101 0.4926649905506442 0.5266307012208933\nCPU times: user 27.5 s, sys: 144 ms, total: 27.6 s\nWall time: 27.7 s\n102 0.49777121422780884 0.5281262257698491\nCPU times: user 27.6 s, sys: 148 ms, total: 27.8 s\nWall time: 27.8 s\n103 0.4968581096067199 0.5284308675234687\nCPU times: user 27.6 s, sys: 156 ms, total: 27.8 s\nWall time: 27.8 s\n104 0.4964197547528168 0.5299046540833348\nCPU times: user 27.4 s, sys: 200 ms, total: 27.6 s\nWall time: 27.7 s\n105 0.4913440005767121 0.5263151217006743\nCPU times: user 28.1 s, sys: 128 ms, total: 28.2 s\nWall time: 28.3 s\n106 0.4961575397219524 0.5297127533670265\nCPU times: user 27.6 s, sys: 200 ms, total: 27.8 s\nWall time: 27.9 s\n107 0.4984381690612258 0.534933643447269\nCPU times: user 27.6 s, sys: 164 ms, total: 27.7 s\nWall time: 27.8 s\n108 0.49658512938248256 0.5317331637682016\nCPU times: user 27.5 s, sys: 192 ms, total: 27.7 s\nWall time: 27.7 s\n109 0.494023333610771 0.5296135547617242\nCPU times: user 27.7 s, sys: 168 ms, total: 27.8 s\nWall time: 27.8 s\n110 0.492201909373342 0.524813224634953\nCPU times: user 27.4 s, sys: 148 ms, total: 27.6 s\nWall time: 27.6 s\n111 0.4919881758652085 0.5245682688866382\nCPU times: user 27.4 s, sys: 192 ms, total: 27.6 s\nWall time: 27.7 s\n112 0.49272255331397274 0.5269357817023478\nCPU times: user 27.6 s, sys: 148 ms, total: 27.7 s\nWall time: 27.8 s\n113 0.4943421442856452 0.5303083840595315\nCPU times: user 27.5 s, sys: 180 ms, total: 27.7 s\nWall time: 27.7 s\n114 0.4900385696939978 0.5265484677137737\nCPU times: user 27.5 s, sys: 180 ms, total: 27.7 s\nWall time: 27.7 s\n115 0.4910704495693448 0.5259488989953793\nCPU times: user 27.6 s, sys: 152 ms, total: 27.8 s\nWall time: 27.8 s\n116 0.49046409665653723 0.5303741850597613\nCPU times: user 28.2 s, sys: 156 ms, total: 28.3 s\nWall time: 28.4 s\n117 0.48975035194979594 0.5254327935319062\nCPU times: user 27.6 s, sys: 160 ms, total: 27.8 s\nWall time: 27.8 s\n118 0.4929327625461884 0.5281623437852917\nCPU times: user 27.6 s, sys: 144 ms, total: 27.8 s\nWall time: 27.8 s\n119 0.4899386479626272 0.5256738066049488\nCPU times: user 27.4 s, sys: 188 ms, total: 27.6 s\nWall time: 27.6 s\n120 0.4902729889975912 0.5274180970076864\nCPU times: user 27.6 s, sys: 192 ms, total: 27.8 s\nWall time: 27.8 s\n121 0.49240599827691994 0.52804162204287\nCPU times: user 27.7 s, sys: 216 ms, total: 27.9 s\nWall time: 28 s\n122 0.49402390144273994 0.52917743603616\nCPU times: user 27.5 s, sys: 160 ms, total: 27.7 s\nWall time: 27.7 s\n123 0.4886365239148448 0.5252134620466888\nCPU times: user 27.6 s, sys: 140 ms, total: 27.7 s\nWall time: 27.7 s\n124 0.49061565984426814 0.5277560153399176\nCPU times: user 27.3 s, sys: 176 ms, total: 27.5 s\nWall time: 27.5 s\n125 0.4875911319947177 0.5263195455259975\nCPU times: user 27.4 s, sys: 164 ms, total: 27.6 s\nWall time: 27.6 s\n126 0.4885870155251131 0.5270579631529478\nCPU times: user 27.4 s, sys: 156 ms, total: 27.5 s\nWall time: 27.6 s\n127 0.4888371279512052 0.5267063532296516\nCPU times: user 27.8 s, sys: 116 ms, total: 27.9 s\nWall time: 27.9 s\n128 0.48649746291128404 0.5229784539711154\nCPU times: user 27.3 s, sys: 216 ms, total: 27.5 s\nWall time: 27.5 s\n129 0.4906327937746713 0.5313291437045311\nCPU times: user 27.3 s, sys: 176 ms, total: 27.5 s\nWall time: 27.5 s\n130 0.4909287980258668 0.5287135629229975\nCPU times: user 27.5 s, sys: 136 ms, total: 27.6 s\nWall time: 27.6 s\n131 0.48966650791811067 0.529364531893315\nCPU times: user 27.3 s, sys: 156 ms, total: 27.5 s\nWall time: 27.5 s\n132 0.4918112738562272 0.5286612632889485\nCPU times: user 27.7 s, sys: 180 ms, total: 27.9 s\nWall time: 27.9 s\n133 0.48807046647938207 0.5265618930200476\nCPU times: user 27.5 s, sys: 140 ms, total: 27.6 s\nWall time: 27.6 s\n134 0.49022973058886676 0.5293538979997258\n","name":"stdout"},{"output_type":"stream","text":"CPU times: user 27.6 s, sys: 160 ms, total: 27.7 s\nWall time: 27.8 s\n135 0.4862470316248462 0.5255694689484869\nCPU times: user 27.4 s, sys: 148 ms, total: 27.5 s\nWall time: 27.5 s\n136 0.48838280498643166 0.5268812469129524\nCPU times: user 27.6 s, sys: 140 ms, total: 27.7 s\nWall time: 27.7 s\n137 0.48860676589778546 0.526295969128337\nCPU times: user 27.7 s, sys: 140 ms, total: 27.9 s\nWall time: 27.9 s\n138 0.48919435704667835 0.5252893181658441\nCPU times: user 27.4 s, sys: 184 ms, total: 27.6 s\nWall time: 27.6 s\n139 0.4901016305053089 0.5241411182567416\nCPU times: user 27.4 s, sys: 140 ms, total: 27.6 s\nWall time: 27.6 s\n140 0.48703219215357335 0.5239828345452137\nCPU times: user 27.5 s, sys: 156 ms, total: 27.7 s\nWall time: 27.7 s\n141 0.4918049615408757 0.527096513807903\nCPU times: user 27.9 s, sys: 192 ms, total: 28 s\nWall time: 28.1 s\n142 0.49048083552821997 0.5277655829380985\nCPU times: user 27.3 s, sys: 204 ms, total: 27.5 s\nWall time: 27.5 s\n143 0.4875119611193814 0.5248415889861328\nCPU times: user 27.3 s, sys: 228 ms, total: 27.6 s\nWall time: 27.6 s\n144 0.4936365451857297 0.5304223140623242\nCPU times: user 27.5 s, sys: 144 ms, total: 27.7 s\nWall time: 27.7 s\n145 0.4902581884901341 0.5273338761702955\nCPU times: user 27.3 s, sys: 160 ms, total: 27.5 s\nWall time: 27.5 s\n146 0.4875456026405873 0.5229517587580422\nCPU times: user 27.3 s, sys: 116 ms, total: 27.4 s\nWall time: 27.4 s\n147 0.4957309393507744 0.5306771663187905\nCPU times: user 27.5 s, sys: 124 ms, total: 27.6 s\nWall time: 27.7 s\n148 0.48923606329180797 0.5241096830013455\nCPU times: user 27.6 s, sys: 168 ms, total: 27.8 s\nWall time: 27.8 s\n149 0.4860335460510177 0.5212009352331769\nCPU times: user 27.5 s, sys: 160 ms, total: 27.6 s\nWall time: 27.7 s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}